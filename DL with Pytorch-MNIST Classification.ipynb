{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a991e7f539673da033393d34767c7335318ab9a"
   },
   "source": [
    "**Agenda:**\n",
    "<br>\n",
    "For this tutorial in  Deep Learning(DL) with Pytorch, we are going to explore Multi Layered Perceptron architecture and learn Pytorch by implementing  algorithms under a certain usecase.We will cover the following:\n",
    "1. Deep Learning basics with Pytorch\n",
    "2. Multilayered Perceptron (MLP) implemention on  MNIST\n",
    "<br>\n",
    "\n",
    "[Kaggle Kernel to run this notebook](https://www.kaggle.com/u6yuvi/dl-with-pytorch-mnist-classification?scriptVersionId=9647143)\n",
    "\n",
    "Lets get started !!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f02da80b362a4233b75cb0f9e9656525e37befa"
   },
   "source": [
    "![](images/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6145a827010b47e713d5bcdb6f89d8042040d75f"
   },
   "source": [
    "# **1. Deep Learning basics with Pytorch**\n",
    "<br>\n",
    "In this part we will cover the following:\n",
    "1. Learn to play with tensors on numpy and pytorch \n",
    "2. Learn to build a simple feed forward network from scratch with random data \n",
    "3. Learn to build an end to end MLP for MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:21:32.419945Z",
     "start_time": "2019-02-04T11:21:27.622375Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(\"List of files\",os.listdir(\"../input\"))\n",
    "import torch\n",
    "import numpy as np\n",
    "print(\"Torch Version:\",torch.__version__)\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e8017c3ed94f083df4e2bf071f7f5f422c40ca1"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "8f08b918b1e2513ad7c1f382cfba39b0205aba6e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def test_network(net, trainloader):\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    # Create Variables for the inputs and targets\n",
    "    inputs = Variable(images)\n",
    "    targets = Variable(images)\n",
    "\n",
    "    # Clear the gradients from all Variables\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass, then backward pass, then update weights\n",
    "    output = net.forward(inputs)\n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def view_recon(img, recon):\n",
    "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
    "        reconstruction also a PyTorch Tensor\n",
    "    '''\n",
    "\n",
    "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
    "    axes[0].imshow(img.numpy().squeeze())\n",
    "    axes[1].imshow(recon.data.numpy().squeeze())\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "        ax.set_adjustable('box-forced')\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cc2337505994f4530913183436b9f4bf8a118599"
   },
   "source": [
    "## Tensors\n",
    "It turns out neural network computations are just a bunch of linear algebra operations on *tensors*, a generalization of matrices. A vector is a 1-dimensional tensor, a matrix is a 2-dimensional tensor, an array with three indices is a 3-dimensional tensor (RGB color images for example). The fundamental data structure for neural networks are tensors and PyTorch (as well as pretty much every other deep learning framework) is built around tensors.\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
    "\n",
    "<img src=\"images/tensor_examples.svg\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a randomly initialized 5x3 matrix:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:21:36.971841Z",
     "start_time": "2019-02-04T11:21:36.623384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7815, 0.2967, 0.4816],\n",
      "        [0.6431, 0.3733, 0.6138],\n",
      "        [0.6856, 0.1746, 0.7436],\n",
      "        [0.8290, 0.2109, 0.1401],\n",
      "        [0.2138, 0.2844, 0.9311]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:22:21.040158Z",
     "start_time": "2019-02-04T11:22:21.033606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1afe587702c9d925968dc34d4e7f515b700d9089"
   },
   "source": [
    "### Numpy to Torch and back\n",
    "\n",
    "PyTorch has a great feature for converting between Numpy arrays and Torch tensors. Let us see how easy it is to switch between the two\n",
    "\n",
    "### Ceate a tensor using numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "35d8b903e1564ee833e2d0ed2ea00d40b61aa16e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Numpy array:\n",
      " [[-0.33874001  0.60472039 -0.15318415]\n",
      " [-0.09156023 -1.26439588 -0.43720659]\n",
      " [ 0.58556643  0.06881291  2.20322407]\n",
      " [-1.20236525 -0.78030075  0.33184404]\n",
      " [ 0.12752615  0.02692143 -1.12968127]]\n"
     ]
    }
   ],
   "source": [
    "np_array=np.random.randn(5,3)\n",
    "print(f' Numpy array:\\n {np_array}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1d82db999b723fa737510352cf47d96a62b8d63b"
   },
   "source": [
    "### Convert to torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1cbd6fd48cf54645f924d354fc9fb5856bf1ddc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch tensor:\n",
      " tensor([[-0.3387,  0.6047, -0.1532],\n",
      "        [-0.0916, -1.2644, -0.4372],\n",
      "        [ 0.5856,  0.0688,  2.2032],\n",
      "        [-1.2024, -0.7803,  0.3318],\n",
      "        [ 0.1275,  0.0269, -1.1297]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "torch_tensor=torch.from_numpy(np_array)\n",
    "print(f'Torch tensor:\\n {torch_tensor}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "31fe8979751ba061cc81055bbc5079bed1cb0124"
   },
   "source": [
    "### Convert back to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "e72bac0d8c4870f97b1d1724c0bce3fd84b50450"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33874001,  0.60472039, -0.15318415],\n",
       "       [-0.09156023, -1.26439588, -0.43720659],\n",
       "       [ 0.58556643,  0.06881291,  2.20322407],\n",
       "       [-1.20236525, -0.78030075,  0.33184404],\n",
       "       [ 0.12752615,  0.02692143, -1.12968127]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "532f4e612d823389740276fdb2f1d0c9d69cb78d"
   },
   "source": [
    "***An important thing to note here is memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well.*       \n",
    "Let see what does it mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "7a08bc968bbb69b18d7d376748f7a5333f931efe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6613, 2.6047, 1.8468],\n",
       "        [1.9084, 0.7356, 1.5628],\n",
       "        [2.5856, 2.0688, 4.2032],\n",
       "        [0.7976, 1.2197, 2.3318],\n",
       "        [2.1275, 2.0269, 0.8703]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 2 to PyTorch Tensor, in place\n",
    "torch_tensor.add_(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15c233bd4f3539d1cf8c07878d01802607a6ab89"
   },
   "source": [
    "###  Numpy array matches new values from Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "3d4047f95de1ca8055e276de3246da2c6a01ccee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.66125999, 2.60472039, 1.84681585],\n",
       "       [1.90843977, 0.73560412, 1.56279341],\n",
       "       [2.58556643, 2.06881291, 4.20322407],\n",
       "       [0.79763475, 1.21969925, 2.33184404],\n",
       "       [2.12752615, 2.02692143, 0.87031873]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b183396c1d82a600e1c3b1848e94e3ce5a6fbe28"
   },
   "source": [
    " ## Simple Neural Network using Pytorch \n",
    " Let us see how we can use PyTorch to build a simple neural network.\n",
    "![](images/simple_neuron.PNG)\n",
    "\n",
    "Mathematically this looks like: \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= f(w_1 x_1 + w_2 x_2 + b) \\\\\n",
    "y &= f\\left(\\sum_i w_i x_i +b \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "With vectors this is the dot/inner product of two vectors:\n",
    "\n",
    "$$\n",
    "h = \\begin{bmatrix}\n",
    "x_1 \\, x_2 \\cdots  x_n\n",
    "\\end{bmatrix}\n",
    "\\cdot \n",
    "\\begin{bmatrix}\n",
    "           w_1 \\\\\n",
    "           w_2 \\\\\n",
    "           \\vdots \\\\\n",
    "           w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "496c485f3e7f43a27bdce042df78fa11eb296631"
   },
   "source": [
    "With the basics covered, it's time to explore how we can use PyTorch to build a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93562b119ff2797b3660bb0968bc6c31e890b7e5"
   },
   "source": [
    "###  Generate some random data \n",
    " We will create a tensor with shape (1, 5), one row and five columns, that contains values randomly distributed according to the normal distribution with a mean of zero and standard deviation of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "fd1ee538877f19c8a2cfac8ea123ecbdb2f4a94d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Inout features:3\n"
     ]
    }
   ],
   "source": [
    "features=torch.randn(1,3)\n",
    "print(f'Number of Inout features:{features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b0673d28508dd5eed49da6731c4cc1408f1efd5c"
   },
   "source": [
    "### Initialize Weights and Biases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7f39730f8dbaff0834b223744d0bab6bfc516e2c"
   },
   "source": [
    "Weights = torch.randn_like(features) creates another tensor with the same shape as features, again containing values from a normal distribution.\n",
    "\n",
    "Finally, bias = torch.randn((1, 1)) creates a single value from a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "3d2b5d527e0650f3d3c1942a5ee1da56bbbac7de"
   },
   "outputs": [],
   "source": [
    "n_input=features.shape[1]\n",
    "n_hidden=2\n",
    "n_output=1\n",
    "#Weights for input to hidden layer\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "W2=torch.randn(n_hidden,n_output)\n",
    "#Bias term for hidden and output layer\n",
    "B1=torch.randn(n_hidden)\n",
    "B2=torch.randn(n_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "cd62c805fb7363693b56ec9dbcd00a8c404adcba"
   },
   "outputs": [],
   "source": [
    "#Using a Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return(1/1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fbfeec62cfa4a35cb829897b71a4450b70ec8392"
   },
   "source": [
    "### Calculate Weight and Biases\n",
    "We will calculate the output for this multi-layer network using the weights `W1` & `W2`, and the biases, `B1` & `B2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "bd98acc8aa8bb1d2fe06cb77ffd4a5054c07a40b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer activations:tensor([[1.4678, 2.2964]])\n",
      "Output of the network:tensor([[5.4772]])\n"
     ]
    }
   ],
   "source": [
    "h1=activation(torch.matmul(features,W1)+B1)\n",
    "print(f'Hidden Layer activations:{h1}')\n",
    "out=activation(torch.matmul(h1,W2)+B2)\n",
    "print(f'Output of the network:{out}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21b8946d94159fc86b191a82bbbb4e34d2289f53"
   },
   "source": [
    "## Building our Network\n",
    "Now we're going to build a larger network that can solve a (formerly) difficult problem, identifying text in an image using MNIST data\n",
    "For now our goal will be to build a neural network that can take one of these images and predict the digit in the image.First, let's try to build this network for this dataset using weight matrices and matrix multiplications. Then, we'll see how to do it using PyTorch's `nn` module which provides a much more convenient and powerful method for defining network architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4c2229e3f3534db73e8d22ba73485022765f3af"
   },
   "source": [
    "![](images/mnist.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d2974386321060bd66905127f3a48b9f1b177310"
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import helper\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "237092ef839e8201ecc710f53ed7154e0f865b2e"
   },
   "source": [
    "### Load Dataset \n",
    "First up, we need to get our dataset.Right now we will be using MNIST dataset which is already in`torchvision` package. The code below will download the MNIST dataset, then create training and test datasets for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:27:05.872957Z",
     "start_time": "2019-02-04T11:26:45.305539Z"
    },
    "_uuid": "45cde9b49e2c0e1802ff640ebab0d766233e6abe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is dataset ?\n",
    "Dataset contains two data methods `__getitem__` and `__len__` so using these methods. we can directly call a single data with index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:31:37.364338Z",
     "start_time": "2019-02-04T11:31:37.283418Z"
    }
   },
   "outputs": [],
   "source": [
    "# like this way\n",
    "trainset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### what is dataloader?\n",
    "\n",
    "It simply uses the generator to provide data giving single- or multi-process iterators over the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00ab24a0af33038559ec91ea83458558e4d574bf"
   },
   "source": [
    "We have the training data loaded into trainloader \n",
    "\n",
    "With dataloaded we make  an iterator with iter(trainloader). Later, we'll use this to loop through the dataset for training, like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:04.781132Z",
     "start_time": "2019-02-04T11:38:04.633040Z"
    },
    "_uuid": "9808e8dab8f56248ae40759f20b1e59dad3ede7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "#Printing the size of one image\n",
    "print(images[1].numpy().squeeze().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "f544046855f3efd0eb1d88fb11f0e4e27318d5eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHXhJREFUeJzt3XuwZWV5J+DfKxhaqQhIBUniKMiInUrCPUIgg1xKRyeJYoAZ/jBSUVMxE4ZgZMqpxAvGTBWpjBcujqRiIlWaDElBhSQTolhyF5iUqGEwIhC6QSoKIsNFoCXAN3/sdbTTntOXvXaffc53nqdq1+q91n73957Vq/t31t7rUq21AAB9es68GwAAdh5BDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAd23XeDewMVbUhyQuSbJxzKwAwrf2SPNpa23/Mm3QZ9JmE/AuHBwCsWXP96L6qXlxVf1JV/1xV362qjVX1karaa+Rbb5xFfwAwZxvHvsHc9uir6oAkNybZJ8lfJbk9ySuT/GaS11bVMa21b8+rPwDowTz36P9nJiF/ZmvtpNbaf2utnZDkw0lekeS/z7E3AOhCtdaWf9DJ3vxdmXwkcUBr7dnNlv1wkm8kqST7tNYen+L9b0ly2Gy6BYC5+WJr7fAxbzCvPfrjh+mVm4d8krTWHkvy+STPT3LUcjcGAD2Z13f0rximdyyx/M4kr0lyYJLPLfUmw577YtZP3xoA9GNee/R7DNNHlli+MH/PZegFALq1qs+jX+p7C9/RA8DEvPboF/bY91hi+cL8h5ehFwDo1ryC/mvD9MAllr98mC71HT4AsB3mFfRXD9PXVNW/6mE4ve6YJE8kuXm5GwOAnswl6Ftr/5Tkykwu2P8bWyx+f5Ldk3xymnPoAYDvm+fBeP85k0vgnl9VJyb5apIjMznH/o4kvzPH3gCgC3O7BO6wV39EkoszCfh3JjkgyXlJjnKdewAYb66n17XWvp7kV+bZAwD0bK63qQUAdi5BDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAd23XeDcAs7L777qPqr7/++qlrDz300FFj33333VPXHnDAAaPGBvpnjx4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOuZ+9HThXe9616j6gw8+eOra1tqosffdd9+paz//+c+PGnutOv/880fV33TTTVPX3nvvvaPGhh01tz36qtpYVW2Jxzfn1RcA9GTee/SPJPnIIvO/s9yNAECP5h30D7fWzplzDwDQLQfjAUDH5r1Hv1tVvSnJS5I8nuTWJNe11p6Zb1sA0Id5B/2+ST65xbwNVfUrrbVrt1VcVbcssWj96M4AoAPz/Oj+E0lOzCTsd0/y00n+MMl+Sf6uqqY/3wkASDLHPfrW2vu3mHVbkrdX1XeSvDPJOUneuI33OHyx+cOe/mEzaBMAVrWVeDDeRcP02Ll2AQAdWIlB/61huvtcuwCADqzEoD9qmN491y4AoANzCfqq+omq+oE99qraL8mFw9NPLWdPANCjeR2M95+SvLOqrktyT5LHkhyQ5OeTrEtyRZL/MafeAKAb8wr6q5O8IsmhSY7J5Pv4h5PckMl59Z9sY28JBgCkesxTp9etTkceeeTUtddcc82osX/oh35o6tqqGjX2av03uFZ/7iS5//77p64988wzR4196aWXjqpn1fniUqeSb6+VeDAeADAjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBju867AViw1157TV075n7y8/alL31p6trbb799hp3smLH3o3/xi188qv7nfu7nRtWPse+++05de+65544a2/3o2VH26AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADrmNrWsGK9+9aunrh17y9QxTjjhhFH111xzzWwaYbuNXefHHnvs1LUvfelL5zb2ddddN2psVid79ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMfejZ8U46qijpq5trc2wkx3jfvKrzz777DO3se+5555R9e4pz46yRw8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxQQ8AHRP0ANAxt6mFkc4444xR9RdeeOGMOllb9t9//6lrX/rSl86wkx2zYcOGuY3N2jSTPfqqOqWqLqiq66vq0apqVfWpbdQcXVVXVNVDVfVkVd1aVWdV1S6z6AkAmN0e/buTHJzkO0nuS7J+ay+uqjckuSzJpiR/nuShJL+Y5MNJjkly6oz6AoA1bVbf0b8jyYFJXpDk17f2wqp6QZI/SvJMkuNaa29trf3XJIckuSnJKVV12oz6AoA1bSZB31q7urV2Z2utbcfLT0nyI0kuaa19YbP32JTJJwPJNn5ZAAC2zzyOuj9hmH56kWXXJXkiydFVtdvytQQAfZpH0L9imN6x5YLW2tNJNmRy7MDLlrMpAOjRPE6v22OYPrLE8oX5e27rjarqliUWbfVgQABYK1wwBwA6No89+oU99j2WWL4w/+FtvVFr7fDF5g97+ofteGsA0Jd57NF/bZgeuOWCqto1yf5Jnk5y93I2BQA9mkfQXzVMX7vIsmOTPD/Jja217y5fSwDQp3kE/aVJHkxyWlUdsTCzqtYl+b3h6cfm0BcAdGcm39FX1UlJThqe7jtMf7aqLh7+/GBr7ewkaa09WlW/mkngX1NVl2RyCdzXZ3Lq3aWZXBYXABhpVgfjHZLk9C3mvSzfPxf+niRnLyxorV1eVa9K8jtJTk6yLsldSX4ryfnbeYU9AGAbZhL0rbVzkpyzgzWfT/IfZjE+ALA496NnxTj//POnrj3qqKNm2MmOefOb3zyqfswHWB/96EdHjT3GhRdeOKr+TW9606j65z73uVPXrlu3btTYTz311NS173vf+0aNDTvKBXMAoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA65ja1rBj333//1LWbNm0aNfbznve8qWuPOOKIUWOPqb/gggtGjc10PvGJT0xdu2HDhhl2Attmjx4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOlattXn3MHNVdUuSw+bdB8tnv/32G1X/la98ZeraMfeyT5LV+m+wqkbVr9afOxn3sz/55JOjxv7TP/3TqWv/4A/+YNTYd95556h6pvLF1trhY97AHj0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DHBD0AdEzQA0DH3KaWLuy///6j6m+77bapa1fzbWq/9KUvTV27adOmUWPvtddeo+rXr18/qn6MMbepneff9+OPPz6q/rLLLpu69v3vf/+osTdu3DiqfhVzm1oAYGmCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGPuR8+K8ZKXvGTq2ptvvnnU2C960Yumrh1zb/Jk3P3JL7roolFjn3nmmVPXPvPMM6PGXrdu3aj6fffdd1T9GHvuuefUtWefffaosdevXz917aGHHjpq7DHb+m233TZq7IMOOmhU/Sq2Mu5HX1WnVNUFVXV9VT1aVa2qPrXEa/cbli/1uGQWPQEAya4zep93Jzk4yXeS3Jdke37l/Ickly8yf9yvfQDA98wq6N+RScDfleRVSa7ejpovt9bOmdH4AMAiZhL0rbXvBfvY7ysBgNmZ1R79NH6sqn4tyd5Jvp3kptbarXPsBwC6M8+gf/Xw+J6quibJ6a21e7fnDYaj6xcz/WGpANCReZxH/0SSDyQ5PMlew2Phe/3jknyuqnafQ18A0J1l36NvrT2Q5L1bzL6uql6T5IYkRyZ5W5LztuO9Fj230Hn0ADCxYq6M11p7OsnHh6fHzrMXAOjFign6wbeGqY/uAWAGVlrQHzVM755rFwDQiWUP+qo6rKp+YNyqOjGTC+8kyaKXzwUAdsxMDsarqpOSnDQ8XbjTxM9W1cXDnx9srS3cyeFDSV5eVTdmcjW9JDkoyQnDn9/TWrtxFn0BwFo3q6PuD0ly+hbzXjY8kuSeJAtB/8kkb0zyM0lel+S5Se5P8hdJLmytXT+jngBgzZvVJXDPSXLOdr72j5P88SzGBQC2zv3oWTFOO+20qWv/7M/+bIad7Jjf//3fH1V/3333bftFS/joRz86amzWlr/+678eVf8Lv/ALM+pkx33oQx+auvbss8/e9otWrpVxP3oAYGUS9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMUEPAB0T9ADQMbepZWbWrVs3qv6WW26Zunb9+vWjxh5jl112mdvYsJweffTRqWt33333UWPffvvtU9cefviou7xm06ZNo+pHcptaAGBpgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBju867Afrxoz/6o6Pq53lP+RtuuGFuY8Nqceedd05de8ghh4wau7U2de2zzz47auzVzh49AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAx9ymFpK88pWvnHcLsNMdd9xxo+oPPfTQqWvH3GY2SR5++OGpa5966qlRY6929ugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGOCHgA6JugBoGPuR8/MbNiwYVT9Bz7wgalr3/ve944ae7fddpu6dtOmTaPGPu+886au/eAHPzhq7AceeGBUPavLKaecMrexq2pU/ZVXXjmjTtae0Xv0VbV3Vb2tqv6yqu6qqier6pGquqGq3lpVi45RVUdX1RVV9dBQc2tVnVVVu4ztCQCYmMUe/alJPpbkG0muTnJvkhcl+aUkH0/yuqo6tbXWFgqq6g1JLkuyKcmfJ3koyS8m+XCSY4b3BABGmkXQ35Hk9Un+trX27MLMqvrtJH+f5ORMQv+yYf4LkvxRkmeSHNda+8Iw/z1JrkpySlWd1lq7ZAa9AcCaNvqj+9baVa21v9k85If530xy0fD0uM0WnZLkR5JcshDyw+s3JXn38PTXx/YFAOz8o+7/ZZg+vdm8E4bppxd5/XVJnkhydFVNf3QUAJBkJx51X1W7Jnnz8HTzUH/FML1jy5rW2tNVtSHJTyZ5WZKvbmOMW5ZYtH7HugWAPu3MPfpzk/xUkitaa5/ZbP4ew/SRJeoW5u+5sxoDgLVip+zRV9WZSd6Z5PYkv7wzxkiS1trhS4x/S5LDdta4ALBazHyPvqrOSHJekn9Mcnxr7aEtXrKwx75HFrcw/+FZ9wYAa81Mg76qzkpyQZLbMgn5by7ysq8N0wMXqd81yf6ZHLx39yx7A4C1aGZBX1XvyuSCN1/OJOSXurbmVcP0tYssOzbJ85Pc2Fr77qx6A4C1aiZBP1zs5twktyQ5sbX24FZefmmSB5OcVlVHbPYe65L83vD0Y7PoCwDWutEH41XV6Ul+N5Mr3V2f5MxFbl6wsbV2cZK01h6tql/NJPCvqapLMrkE7uszOfXu0kwuiwsAjDSLo+73H6a7JDlriddcm+TihSettcur6lVJfieTS+SuS3JXkt9Kcv7m18UHAKZXPWaq0+tWp3322Wfq2muvvXbU2Ace+APHhm63sbffHPNv8LHHHhs19le+8pWpaz/72c+OGvvmm28eVf+Wt7xl6tof//EfHzX2anXEEUds+0Vb8ZznTP9t7xe+8IVtv2gr3vCGN0xdu8pvx/zFpU4l3147+xK4AMAcCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COuR89XRhzL/skefvb3z517RlnnDFq7L333ntU/bxU1aj61fx/z5iffTX/3I899tjUtXvuuecMO1lT3I8eAFiaoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjgl6AOiYoAeAjrlNLYz0whe+cFT9IYccMnXtW97yllFjn3zyyVPX7rbbbqPGXs3/98zzNrU33HDD1LWXXnrpqLEvv/zyqWu//vWvjxp7DXObWgBgaYIeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY4IeADom6AGgY+5HDwArl/vRAwBLE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdE/QA0DFBDwAdGx30VbV3Vb2tqv6yqu6qqier6pGquqGq3lpVz9ni9ftVVdvK45KxPQEAE7vO4D1OTfKxJN9IcnWSe5O8KMkvJfl4ktdV1amttbZF3T8kuXyR97ttBj0BAJlN0N+R5PVJ/ra19uzCzKr67SR/n+TkTEL/si3qvtxaO2cG4wMASxj90X1r7arW2t9sHvLD/G8muWh4etzYcQCAHTeLPfqt+Zdh+vQiy36sqn4tyd5Jvp3kptbarTu5HwBYU3Za0FfVrknePDz99CIvefXw2LzmmiSnt9bu3Vl9AcBasjP36M9N8lNJrmitfWaz+U8k+UAmB+LdPcw7KMk5SY5P8rmqOqS19vi2BqiqW5ZYtH7apgGgJ/WDB8PP4E2rzkxyXpLbkxzTWntoO2p2TXJDkiOTnNVaO287arYW9M/f/o4BYEX6Ymvt8DFvMPM9+qo6I5OQ/8ckJ25PyCdJa+3pqvp4JkF/7PAe26pZ9IcffgE4bLubBoBOzfTKeFV1VpILMjkX/vjhyPsd8a1huvss+wKAtWpmQV9V70ry4SRfziTkH5jibY4apndv9VUAwHaZSdBX1XsyOfjulkw+rn9wK689bMvL4g7zT0zyjuHpp2bRFwCsdaO/o6+q05P8bpJnklyf5Myq2vJlG1trFw9//lCSl1fVjUnuG+YdlOSE4c/vaa3dOLYvAGA2B+PtP0x3SXLWEq+5NsnFw58/meSNSX4myeuSPDfJ/Un+IsmFrbXrZ9ATAJCddHrdvDnqHoBOjD69zv3oAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOiboAaBjgh4AOtZr0O837wYAYAb2G/sGu86giZXo0WG6cYnl64fp7Tu/lW5YZ9Ox3qZjve0462w6K3m97Zfv59nUqrU2vpVVpqpuSZLW2uHz7mW1sM6mY71Nx3rbcdbZdNbCeuv1o3sAIIIeALom6AGgY4IeADom6AGgY2vyqHsAWCvs0QNAxwQ9AHRM0ANAxwQ9AHRM0ANAxwQ9AHRM0ANAx9ZU0FfVi6vqT6rqn6vqu1W1sao+UlV7zbu3lWpYR22Jxzfn3d+8VNUpVXVBVV1fVY8O6+NT26g5uqquqKqHqurJqrq1qs6qql2Wq+9525H1VlX7bWXba1V1yXL3Pw9VtXdVva2q/rKq7hq2nUeq6oaqemtVLfr/+Frf3nZ0vfW8vfV6P/ofUFUHJLkxyT5J/iqTew+/MslvJnltVR3TWvv2HFtcyR5J8pFF5n9nuRtZQd6d5OBM1sF9+f49rRdVVW9IclmSTUn+PMlDSX4xyYeTHJPk1J3Z7AqyQ+tt8A9JLl9k/m0z7GslOzXJx5J8I8nVSe5N8qIkv5Tk40leV1Wnts2ufmZ7SzLFehv0t7211tbEI8lnkrQk/2WL+R8a5l807x5X4iPJxiQb593HSnskOT7Jy5NUkuOGbehTS7z2BUkeSPLdJEdsNn9dJr98tiSnzftnWoHrbb9h+cXz7nvO6+yETEL6OVvM3zeT8GpJTt5svu1tuvXW7fa2Jj66H/bmX5NJaH10i8XvS/J4kl+uqt2XuTVWqdba1a21O9vwP8Q2nJLkR5Jc0lr7wmbvsSmTPdwk+fWd0OaKs4PrjSSttataa3/TWnt2i/nfTHLR8PS4zRbZ3jLVeuvWWvno/vhheuUif+mPVdXnM/lF4Kgkn1vu5laB3arqTUlekskvRbcmua619sx821o1Thimn15k2XVJnkhydFXt1lr77vK1tWr8WFX9WpK9k3w7yU2ttVvn3NNK8S/D9OnN5tnetm2x9bagu+1trQT9K4bpHUssvzOToD8wgn4x+yb55BbzNlTVr7TWrp1HQ6vMkttfa+3pqtqQ5CeTvCzJV5ezsVXi1cPje6rqmiSnt9bunUtHK0BV7ZrkzcPTzUPd9rYVW1lvC7rb3tbER/dJ9himjyyxfGH+nsvQy2rziSQnZhL2uyf56SR/mMn3WX9XVQfPr7VVw/Y3nSeSfCDJ4Un2Gh6vyuTAquOSfG6Nf912bpKfSnJFa+0zm823vW3dUuut2+1trQQ9U2qtvX/4ruv+1toTrbXbWmtvz+QgxuclOWe+HdKr1toDrbX3tta+2Fp7eHhcl8mnb/8nyb9N8rb5djkfVXVmkndmcvbQL8+5nVVja+ut5+1trQT9wm+weyyxfGH+w8vQSy8WDmY5dq5drA62vxlqrT2dyelRyRrc/qrqjCTnJfnHJMe31h7a4iW2t0Vsx3pbVA/b21oJ+q8N0wOXWP7yYbrUd/j8oG8N01X5UdYyW3L7G74v3D+Tg4LuXs6mVrk1uf1V1VlJLsjknO7jhyPIt2R728J2rretWdXb21oJ+quH6WsWuRrSD2dyAYknkty83I2tYkcN0zXzn8UIVw3T1y6y7Ngkz09y4xo+Anoaa277q6p3ZXLBmy9nElYPLPFS29tmdmC9bc2q3t7WRNC31v4pyZWZHED2G1ssfn8mv6V9srX2+DK3tqJV1U8sdvBJVe2X5MLh6VYv+0qS5NIkDyY5raqOWJhZVeuS/N7w9GPzaGwlq6rDFru8a1WdmOQdw9M1sf1V1XsyOYjsliQnttYe3MrLbW+DHVlvPW9vtVauW7HIJXC/muTITM6xvyPJ0c0lcP+VqjonkwNXrktyT5LHkhyQ5OczucrWFUne2Fp7al49zktVnZTkpOHpvkn+fSa/7V8/zHuwtXb2Fq+/NJNLkl6SySVJX5/JqVCXJvmPa+EiMjuy3oZTml6eyb/b+4blB+X754m/p7W2EFzdqqrTk1yc5JlMPn5e7Gj6ja21izerWfPb246ut663t3lfmm85H0n+TSani30jyVOZhNdHkuw1795W4iOTU0v+VyZHqD6cyUUmvpXks5mch1rz7nGO6+acTC6XudRj4yI1x2Tyy9H/S/Jkkv+byZ7CLvP+eVbiekvy1iT/O5MrWn4nk0u63pvJtdv/3bx/lhW0zlqSa2xv49Zbz9vbmtmjB4C1aE18Rw8Aa5WgB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6JigB4COCXoA6Nj/B3LtKPk3Al/bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Look at the image\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:08.273406Z",
     "start_time": "2019-02-04T11:38:08.264208Z"
    },
    "_uuid": "b11c0c543d20cfb96cbb0635eea5f93e37c58cb0"
   },
   "outputs": [],
   "source": [
    "#Sigmoid Activation Function\n",
    "def activation(x):\n",
    "    return (1/(1+torch.exp(-x)))\n",
    "\n",
    "#Input 64x784\n",
    "inputs=images.view(images.shape[0],-1)\n",
    "#Number of input features-784\n",
    "n_input=inputs.shape[1]\n",
    "#Number of neurons in hidden layer-256\n",
    "n_hidden=256\n",
    "#Number of output neuron-10\n",
    "n_out=10\n",
    "#Weight at hidden neuron-784x256\n",
    "W1=torch.randn(n_input,n_hidden)\n",
    "#Bias at hidden neuron-256\n",
    "B1=torch.randn(n_hidden)\n",
    "#Weight at output neuron-256x10\n",
    "W2=torch.randn(n_hidden,n_out)\n",
    "#Bias at output neuron-10\n",
    "B2=torch.randn(n_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:13.520858Z",
     "start_time": "2019-02-04T11:38:13.510149Z"
    },
    "_uuid": "e494abcbcf8bf4e1210b1acdc0790ca77f826e21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of a batch of an image: torch.Size([64, 1, 28, 28])\n",
      "Shape of the input to the network: torch.Size([64, 784])\n",
      "Shape of the input features: 784\n",
      "Shape of the Weight matrix of neurons in the hidden layer torch.Size([784, 256])\n",
      "Shape of the Bias vector of neurons in the hidden layer torch.Size([256])\n",
      "Shape of the Weight matrix of neurons in the output layer torch.Size([256, 10])\n",
      "Shape of the Bias vector of neurons in the output layer torch.Size([256, 10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of a batch of an image:\",images.shape)\n",
    "print(\"Shape of the input to the network:\",inputs.shape)\n",
    "print(\"Shape of the input features:\",n_input)\n",
    "print(\"Shape of the Weight matrix of neurons in the hidden layer\",W1.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the hidden layer\",B1.shape)\n",
    "print(\"Shape of the Weight matrix of neurons in the output layer\",W2.shape)\n",
    "print(\"Shape of the Bias vector of neurons in the output layer\",W2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:23.336380Z",
     "start_time": "2019-02-04T11:38:22.958331Z"
    },
    "_uuid": "e751026ecf95253bf33db0462ce8bc250c082bb7"
   },
   "outputs": [],
   "source": [
    "#Hidden layer activations\n",
    "h1=activation(torch.mm(inputs,W1)+B1)\n",
    "#Output layer activations\n",
    "out=activation(torch.mm(h1,W2)+B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:26.658141Z",
     "start_time": "2019-02-04T11:38:26.649686Z"
    },
    "_uuid": "2cb2a0f4a6d9852da5d4811e89734c8906bbb878"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Hidden activation of the networktorch.Size([64, 256])\n",
      "Shape of the Output of the networktorch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the Hidden activation of the network{h1.shape}')\n",
    "print(f'Shape of the Output of the network{out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:38:38.560819Z",
     "start_time": "2019-02-04T11:38:38.553507Z"
    },
    "_uuid": "66671445031ee39d4142f84c832b2ab097f6d14a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.9971e-01, 9.9513e-01, 2.3973e-08, 3.6122e-04, 5.9004e-05, 5.2853e-02,\n",
       "        3.8646e-03, 1.0000e+00, 4.6131e-01, 1.0000e+00])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us see the network output to one of the feeded input image\n",
    "out[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c7ab4cad2d8a2d619e0b376780e0d5b2dfa7be3"
   },
   "source": [
    "Now we have 10 outputs for our network. This raw output is usually called **logits or scores**.\n",
    "<br>\n",
    "However,We want to pass in an image to our network and get out a probability distribution over the classes that tells us the likely class(es) the image belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1903f5520e57c8ca69b4252ed7a7c4d5e5beb51a"
   },
   "source": [
    "\n",
    "### Probability Distribution using Softmax\n",
    "To calculate this probability distribution, we often use the [softmax function](https://en.wikipedia.org/wiki/Softmax_function)\n",
    "$$\n",
    "\\Large \\sigma(x_i) = \\cfrac{e^{x_i}}{\\sum_k^K{e^{x_k}}}\n",
    "$$\n",
    "What this does is squish each input $x_i$ between 0 and 1 and normalizes the values to give you a proper probability distribution where the probabilites sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:41.701155Z",
     "start_time": "2019-02-04T11:40:41.697492Z"
    },
    "_uuid": "f4d7ba5cc02acf1610fa113490099e51e84978aa"
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return(torch.exp(x)/torch.sum(torch.exp(x),dim=1).view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdf3ab4229b26432555148c0d1b67f6e857055e6"
   },
   "source": [
    "Let us understand what we are doing above by an example\n",
    "<br>\n",
    "Step 1:Calculating the numerator of the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:42.976206Z",
     "start_time": "2019-02-04T11:40:42.970484Z"
    },
    "_uuid": "d06ddfc05e73456929293906a0ee9672cf2f45a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.7175, 2.7051, 1.0000, 1.0004, 1.0001, 1.0543, 1.0039, 2.7183, 1.5862,\n",
       "         2.7183],\n",
       "        [2.7175, 1.1540, 1.0141, 2.7183, 1.0455, 2.7175, 1.0000, 2.0554, 1.0004,\n",
       "         2.7180]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fd149046af107a72d73208528b3a5cf1a6eb13e"
   },
   "source": [
    "Step 2:For every predicted image output, calculate the sum over the predicted values over all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:45.248689Z",
     "start_time": "2019-02-04T11:40:45.236760Z"
    },
    "_uuid": "2277f07ce4566f91bf8ad70e3969f2c4790e676d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17.5038, 18.1407])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(torch.sum(torch.exp(out[1:3])))\n",
    "#Dim=1 says, we want to take the sum across all columns\n",
    "torch.sum(torch.exp(out[1:3]),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e247c285cf5dfdd02702bc79ddc8e49383bc17c1"
   },
   "source": [
    "Step3:Rearrange the sums in an order for broadcasting to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:40:47.116271Z",
     "start_time": "2019-02-04T11:40:47.106860Z"
    },
    "_uuid": "8c226fe7a4a2e9f31f63ddca18ed71959d9a139d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17.5038],\n",
       "        [18.1407]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ecbcd104b966f3ae051d09048e7d708f992f1a41"
   },
   "source": [
    "Step 3:For every predicted image output, divide the predictions of each class with the sum over all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T11:41:41.871814Z",
     "start_time": "2019-02-04T11:41:41.808608Z"
    },
    "_uuid": "fce3f0e89d812e35f44a46ee5eab0fc85bf05406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1553, 0.1545, 0.0571, 0.0572, 0.0571, 0.0602, 0.0574, 0.1553, 0.0906,\n",
      "         0.1553],\n",
      "        [0.1498, 0.0636, 0.0559, 0.1498, 0.0576, 0.1498, 0.0551, 0.1133, 0.0551,\n",
      "         0.1498]])\n"
     ]
    }
   ],
   "source": [
    "#print(torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1))\n",
    "temp=torch.exp(out[1:3])/torch.sum(torch.exp(out[1:3]),dim=1).view(-1,1)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0973f2a30eacf6d699df25a24ce00f9487f35559"
   },
   "source": [
    "Voila!! We got the softmax output .One last thing to do is check whether the sum across all classes sum to 1 for understanding the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "5f899daaaf970fbb7b821a9cf4f70af1b00a9773"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "da2f00d033b1ef41cf3941998ef34e24167a08cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "probabilities = softmax(out)\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "#print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f9cd86feb1156d1a7ba69037197aabf876735be6"
   },
   "source": [
    "## Building our Network with Pytorch\n",
    "\n",
    "![](images/mlp_mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b0737a96ecaa7d4bcd0f6bc4592961e5ffc8e42"
   },
   "source": [
    "PyTorch provides a module `nn` that makes building networks much simpler. Here I'll show you how to build the same one as above with 784 inputs, 256 hidden units, 10 output units and a softmax output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "e82cac77674746147dc9dd5d9367b21c1e02d40c"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "72a3786079aa4a387146ff066176d5af56b11b4b"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden=nn.Linear(784,256)\n",
    "        self.output=nn.Linear(256,10)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.hidden(x)\n",
    "        x=self.sigmoid(x)\n",
    "        x=self.output(x)\n",
    "        x=self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1546fd3ac7e6ab35a81dfee3e704817627a5618"
   },
   "source": [
    "Let's go through this bit by bit.\n",
    "\n",
    "```python\n",
    "class Network(nn.Module):\n",
    "```\n",
    "\n",
    "Here we're inheriting from `nn.Module`. Combined with `super().__init__()` this creates a class that tracks the architecture and provides a lot of useful methods and attributes. It is mandatory to inherit from `nn.Module` when you're creating a class for your network. The name of the class itself can be anything.\n",
    "\n",
    "```python\n",
    "self.hidden = nn.Linear(784, 256)\n",
    "```\n",
    "\n",
    "This line creates a module for a linear transformation, $x\\mathbf{W} + b$, with 784 inputs and 256 outputs and assigns it to `self.hidden`. The module automatically creates the weight and bias tensors which we'll use in the `forward` method. You can access the weight and bias tensors once the network once it's create at `net.hidden.weight` and `net.hidden.bias`.\n",
    "\n",
    "```python\n",
    "self.output = nn.Linear(256, 10)\n",
    "```\n",
    "\n",
    "Similarly, this creates another linear transformation with 256 inputs and 10 outputs.\n",
    "\n",
    "```python\n",
    "self.sigmoid = nn.Sigmoid()\n",
    "self.softmax = nn.Softmax(dim=1)\n",
    "```\n",
    "\n",
    "Here I defined operations for the sigmoid activation and softmax output. Setting `dim=1` in `nn.Softmax(dim=1)` calculates softmax across the columns.\n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "\n",
    "PyTorch networks created with `nn.Module` must have a `forward` method defined. It takes in a tensor `x` and passes it through the operations you defined in the `__init__` method.\n",
    "\n",
    "```python\n",
    "x = self.hidden(x)\n",
    "x = self.sigmoid(x)\n",
    "x = self.output(x)\n",
    "x = self.softmax(x)\n",
    "```\n",
    "\n",
    "Here the input tensor `x` is passed through each operation a reassigned to `x`. We can see that the input tensor goes through the hidden layer, then a sigmoid function, then the output layer, and finally the softmax function. It doesn't matter what you name the variables here, as long as the inputs and outputs of the operations match the network architecture you want to build. The order in which you define things in the `__init__` method doesn't matter, but you'll need to sequence the operations correctly in the `forward` method.\n",
    "\n",
    "Now we can create a `Network` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "36bc9a286ffafd0a0b1ac7890906092965f5fee0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aae8f6f5e7c42a3df7d79b6e3a20293f3a673b0a"
   },
   "source": [
    "We can define the network somewhat more concisely and clearly using the `torch.nn.functional` module. This is the most common way you'll see networks defined as many operations are simple element-wise functions. We normally import this module as `F`, `import torch.nn.functional as F`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "1ebea291b4d96d74d435885e60bc2a792c4abd12"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "41e688fd7486e6ac4ea420cdc23e464a4e2c3432"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(784, 128)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Hidden layer with sigmoid activation\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        # Output layer with softmax activation\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "30f4a6c129eb490f265d2570e16f86dc96534952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8c3820bb60313a368c0a3d8322b21b7d8adeafeb"
   },
   "source": [
    "### Initializing weights and biases\n",
    "\n",
    "The weights and bias are automatically initialized for you, but it's possible to customize how they are initialized. The weights and biases are tensors attached to the layer you defined, you can get them with `model.fc1.weight` for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "d148d7e2446d76d5ca6a8948d23ec513f103cdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0033, -0.0026, -0.0164,  ..., -0.0308,  0.0194,  0.0055],\n",
      "        [-0.0038,  0.0220,  0.0195,  ...,  0.0263, -0.0158,  0.0255],\n",
      "        [-0.0271,  0.0259, -0.0018,  ..., -0.0255, -0.0197,  0.0196],\n",
      "        ...,\n",
      "        [-0.0226, -0.0048, -0.0072,  ..., -0.0170,  0.0275, -0.0274],\n",
      "        [-0.0028,  0.0030,  0.0137,  ..., -0.0046, -0.0090,  0.0115],\n",
      "        [-0.0302,  0.0081, -0.0323,  ..., -0.0194, -0.0074,  0.0023]],\n",
      "       requires_grad=True) torch.Size([128, 784])\n",
      "Parameter containing:\n",
      "tensor([ 0.0167,  0.0271,  0.0063, -0.0016,  0.0206, -0.0016,  0.0036, -0.0076,\n",
      "         0.0105, -0.0310, -0.0025, -0.0094,  0.0347, -0.0294, -0.0061,  0.0052,\n",
      "         0.0052,  0.0115,  0.0229, -0.0134, -0.0010,  0.0006, -0.0315,  0.0100,\n",
      "        -0.0288,  0.0176,  0.0343,  0.0254, -0.0033,  0.0076, -0.0077, -0.0086,\n",
      "         0.0209, -0.0210,  0.0286,  0.0117, -0.0188,  0.0013, -0.0105, -0.0211,\n",
      "         0.0009,  0.0022, -0.0245,  0.0222, -0.0050, -0.0263, -0.0247, -0.0289,\n",
      "         0.0260,  0.0025,  0.0036, -0.0316,  0.0287, -0.0115,  0.0257,  0.0206,\n",
      "        -0.0044, -0.0181,  0.0273,  0.0284,  0.0059, -0.0242, -0.0130,  0.0023,\n",
      "         0.0158,  0.0281,  0.0183,  0.0060, -0.0267, -0.0293, -0.0307, -0.0172,\n",
      "         0.0064, -0.0238, -0.0104,  0.0190, -0.0297, -0.0215, -0.0191,  0.0142,\n",
      "         0.0049,  0.0286, -0.0052,  0.0046,  0.0253,  0.0225,  0.0188,  0.0005,\n",
      "        -0.0252, -0.0042,  0.0295, -0.0283, -0.0333,  0.0196, -0.0281,  0.0223,\n",
      "         0.0329,  0.0058,  0.0244,  0.0130,  0.0038,  0.0047,  0.0020,  0.0302,\n",
      "         0.0182, -0.0134,  0.0036,  0.0315, -0.0340, -0.0346,  0.0246,  0.0296,\n",
      "        -0.0021,  0.0301,  0.0338,  0.0003,  0.0208,  0.0350, -0.0291,  0.0016,\n",
      "         0.0065, -0.0238, -0.0083,  0.0045, -0.0121, -0.0104, -0.0239,  0.0228],\n",
      "       requires_grad=True) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(model.hidden.weight,model.hidden.weight.shape)\n",
    "print(model.hidden.bias,model.hidden.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a1989c40df55dd4324cad2736e72481c148299d"
   },
   "source": [
    "For custom initialization, we can these tensors in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "dc98f7292fe8d6f40b1ea58b681acf522f500bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set biases to all zeros\n",
    "model.hidden.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "354f3f9fbcf8b0c6808394ea97e794b9f43ffe60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0148,  0.0038, -0.0110,  ..., -0.0021, -0.0139, -0.0037],\n",
       "        [ 0.0014,  0.0066, -0.0124,  ..., -0.0045,  0.0032, -0.0082],\n",
       "        [ 0.0003,  0.0056, -0.0123,  ..., -0.0033,  0.0010, -0.0025],\n",
       "        ...,\n",
       "        [ 0.0148,  0.0076,  0.0159,  ..., -0.0102, -0.0099, -0.0003],\n",
       "        [ 0.0052, -0.0087, -0.0013,  ...,  0.0105, -0.0006,  0.0103],\n",
       "        [-0.0060, -0.0125, -0.0029,  ..., -0.0023, -0.0020,  0.0055]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample from random normal with standard dev = 0.01\n",
    "model.hidden.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "e3b948402fbcd6e8529fe5ebcd00347f1db63a1c"
   },
   "outputs": [],
   "source": [
    "netowrk=Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1eb03d730d47d46308e593ff4debbd6899280bbe"
   },
   "source": [
    "### Forward pass\n",
    "\n",
    "Now that we have a network, let's see what happens when we pass in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "59df5bda3337698adad159777311294b7f8cfce4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 224,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grab some data \n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Resize images into a 1D vector, new shape is (batch size, color channels, image pixels) \n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "\n",
    "# Forward pass through the network\n",
    "img_idx = 0\n",
    "ps = model.forward(images[img_idx,:])\n",
    "\n",
    "img = images[img_idx]\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2103e632ea834fcbd4741de8b9ee7edace23ba6b"
   },
   "source": [
    "As you can see above, our network has basically no idea what this digit is. It's because we haven't trained it yet, , all the weights are random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d611ac89023080d6ee0e42b9369376ed261a777"
   },
   "source": [
    "## Add-on-People from the keras would love this!!!\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential`.\n",
    "Lets try to build the above network using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "e6f5405fe980380825786437c0aa8e94cb8cb92e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=10, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Softmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128]\n",
    "output_size = 10\n",
    "\n",
    "model=nn.Sequential(nn.Linear(input_size,hidden_sizes[0]),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(hidden_sizes[0],output_size),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Softmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "d461b698ae5973918405c9120db6e94194347a27"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 224,
       "width": 423
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])\n",
    "view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d137ebac2a3367c41e6c001f2edf2a37b0b22211"
   },
   "source": [
    "### Access Layers of the network\n",
    "We can access layers  by integer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "0cf54881f8e022928a962d1d83fd5614a97a039e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0072, -0.0288,  0.0269,  ..., -0.0033, -0.0193,  0.0225],\n",
       "        [-0.0107,  0.0125, -0.0244,  ..., -0.0196, -0.0050, -0.0334],\n",
       "        [ 0.0077, -0.0130,  0.0002,  ..., -0.0146,  0.0208,  0.0225],\n",
       "        ...,\n",
       "        [-0.0267, -0.0029,  0.0338,  ..., -0.0104,  0.0205,  0.0012],\n",
       "        [ 0.0327, -0.0182, -0.0025,  ...,  0.0199, -0.0295, -0.0202],\n",
       "        [ 0.0174,  0.0344, -0.0070,  ..., -0.0218,  0.0091,  0.0021]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model[0])\n",
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0499ff7a787fc1885f5998f81f2395fc6bcc4108"
   },
   "source": [
    "### Ordered Dict- Better way to create a network\n",
    "We can also pass in an `OrderedDict` to name the individual layers and operations, instead of using incremental integers. Note that dictionary keys must be unique, so _each operation must have a different name_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "ca7567562b0610e6ec4ec7d98f03032bbe32c061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (hidden): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                      ('hidden', nn.Linear(input_size, hidden_sizes[0])),\n",
    "                      ('relu1', nn.ReLU()),\n",
    "                      ('output', nn.Linear(hidden_sizes[0], output_size)),\n",
    "                      ('softmax', nn.Softmax(dim=1))]))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c67ffda9a2ace0093371017d9abf4bc02a8656dc"
   },
   "source": [
    "### Access Layers using integer or name \n",
    "Now we can access layers  either by integer or name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "6da7947d84c734eea2bf19acc3127bdf87ccce1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Linear(in_features=784, out_features=128, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0197, -0.0322,  0.0337,  ...,  0.0178, -0.0350, -0.0222],\n",
      "        [-0.0309, -0.0018,  0.0267,  ...,  0.0142,  0.0103, -0.0044],\n",
      "        [ 0.0283, -0.0074,  0.0065,  ...,  0.0166, -0.0164,  0.0073],\n",
      "        ...,\n",
      "        [-0.0315, -0.0024,  0.0023,  ..., -0.0095, -0.0017, -0.0276],\n",
      "        [ 0.0227, -0.0242, -0.0264,  ...,  0.0262,  0.0118, -0.0069],\n",
      "        [-0.0097, -0.0049, -0.0082,  ...,  0.0202, -0.0108,  0.0189]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0])\n",
    "print(model.hidden)\n",
    "print(model.hidden.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df59c9d06c7e7d2ec2b6582c6bb0934e2d49c58f"
   },
   "source": [
    "### Recollect everything \n",
    "Before we go ahead and train a neural network to accuractly predict the numbers appearing in the MNIST images,let us recollect the important modules that is necessary for any model training exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f0df7ddfb84bf00cee50f9b916a9c61f1a65aaa9"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:17.978997Z",
     "start_time": "2019-02-04T13:03:17.973595Z"
    },
    "_uuid": "ff53d2bd4296f89b134eb961832043cce0e43e4d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a1f47e2928ea88a7c9b45edb08ea75016b6fca6"
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:07:13.687456Z",
     "start_time": "2019-02-04T13:06:40.910295Z"
    },
    "_uuid": "c2c9d59a82c6bce28a611e1f409ced8b4f8fdc39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor()])\n",
    "trainset=datasets.MNIST('~/.pytorch/MNIST_data/',train=True,transform=transform,download=True)\n",
    "testset=datasets.MNIST('~/.pytorch/MNIST_data/',train=False,transform=transform,download=True)\n",
    "\n",
    "trainloader=torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True,num_workers=0)\n",
    "#will explain later\n",
    "testloader=torch.utils.data.DataLoader(testset,batch_size=64,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7161f89857d013b0f837c620c0ed24657bed1b2"
   },
   "source": [
    "#### Build a feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:47.741595Z",
     "start_time": "2019-02-04T13:03:47.735142Z"
    },
    "_uuid": "0e73fc284a626e4d7bbca629f817585aeb06fdd6"
   },
   "outputs": [],
   "source": [
    "# TODO: Build a feed-forward network in one of the three ways mentioned above:\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfdb486a01347095c7c8d75de1d5b74443bbfd4f"
   },
   "source": [
    "#### Lets run one image through the network to check our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:49.422306Z",
     "start_time": "2019-02-04T13:03:49.121144Z"
    },
    "_uuid": "0864af9a75655db17435ef4940945a7d9532c671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "# Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "# Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits\n",
    "logits = model(images)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d9976b19b6ca3910a3a4855754bdc1e3de1f52f"
   },
   "source": [
    "#### Define a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:52.643210Z",
     "start_time": "2019-02-04T13:03:52.638129Z"
    },
    "_uuid": "22466cb3a58aad481e903428de2642ff67e9bc1f"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:03:55.680366Z",
     "start_time": "2019-02-04T13:03:55.547651Z"
    },
    "_uuid": "2e3bda9d30daf829a8e19537715860ff7c678329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3049, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss with the logits and the labels\n",
    "loss=criterion(logits,labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a7dd6c45e94460f48dd048b35229f74a399a988"
   },
   "source": [
    "## Autograd\n",
    "\n",
    "Now that we know how to calculate a loss, how do we use it to perform backpropagation? Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of operations performed on tensors, then going backwards through those operations, calculating gradients along the way.\n",
    "\n",
    "PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time with `x.requires_grad_(True)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3361f46b9d9dbf06bc4a6b257f472129c2b01e1"
   },
   "source": [
    "Let's see an example to understand it better.Then again we will head back to our modelling task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "5ab21186791f7e319778106ca1ffb327d0847e16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8575, -1.5131],\n",
      "        [ 0.8923, -0.2002]], requires_grad=True)\n",
      "tensor([[3.4504, 2.2896],\n",
      "        [0.7962, 0.0401]], grad_fn=<PowBackward0>)\n",
      "<PowBackward0 object at 0x7f460b3dafd0>\n",
      "tensor(1.6441, grad_fn=<MeanBackward1>)\n",
      "None\n",
      "tensor([[ 0.9288, -0.7566],\n",
      "        [ 0.4462, -0.1001]])\n",
      "tensor([[ 0.9288, -0.7566],\n",
      "        [ 0.4462, -0.1001]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)\n",
    "y = x**2\n",
    "print(y)\n",
    "## grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)\n",
    "z = y.mean()\n",
    "print(z)\n",
    "print(x.grad)\n",
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94d46a1835ad4987ff28365b28ee304d366336dc"
   },
   "source": [
    "## Loss and Autograd together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:04:00.684688Z",
     "start_time": "2019-02-04T13:04:00.535643Z"
    },
    "_uuid": "b0c5e229539704b93a5991c27849bd7b41abae80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 10),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logits = model(images)\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "\n",
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d184b346f9ed4194de74a29675da09076e52e0c4"
   },
   "source": [
    "## Defining the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:04:04.271653Z",
     "start_time": "2019-02-04T13:04:04.266694Z"
    },
    "_uuid": "efadf9e312ec51f9f36d25f043d011c27f4f8fe2"
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91c0777ba686873bd972d96e384c090c9baae3d8"
   },
   "source": [
    "## Training for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:05:20.593146Z",
     "start_time": "2019-02-04T13:04:05.998666Z"
    },
    "_uuid": "6b6ac5071aad8b3232596ed1d4807d73aab09df3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Training loss: 1.1978756191252646\n",
      "Epoch:1 Training loss: 1.0390553001020508\n",
      "Epoch:2 Training loss: 1.2842649309111556\n",
      "Epoch:3 Training loss: 1.2820222057513337\n",
      "Epoch:4 Training loss: 1.7179652771461746\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        optimizer.zero_grad()\n",
    "        output=model.forward(images)\n",
    "        # TODO: Training pass\n",
    "        \n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item(). images.shape[0]\n",
    "    else:\n",
    "        print(f\"Epoch:{e} Training loss: {running_loss/len(trainloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:06:05.063846Z",
     "start_time": "2019-02-04T13:06:04.983101Z"
    },
    "_uuid": "6d837662f725dc7196ba3d24130aa23090dc1616"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "\n",
    "# Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim=1)\n",
    "#helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37a44994683bfe1fee884125d2e58ed08b62720b"
   },
   "source": [
    "## Inference and Validation\n",
    "\n",
    "The goal of validation is to measure the model's performance on data that isn't part of the training set. Typically this is just accuracy, the percentage of classes the network predicted correctly. Other options are precision and recall and top-5 error rate. We'll focus on accuracy here. First I'll do a forward pass with one batch from the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e94326ca7cdc742c2c575294d260c257a97cab87"
   },
   "source": [
    "### Inference on a batch of images\n",
    "Let us try to do this for a batch of images.Before that we will make some changes in our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:08:55.536357Z",
     "start_time": "2019-02-04T13:08:55.509217Z"
    },
    "_uuid": "e4ec78de08b2f24f5032ba181ec7a7d79428261a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "images.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:09:03.958533Z",
     "start_time": "2019-02-04T13:09:03.928394Z"
    },
    "_uuid": "3f2244405b587c87c9347abd1ed4ab150f8d80aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(testloader))\n",
    "img = images.view(images.shape[0], 784)\n",
    "# Get the class probabilities\n",
    "ps = torch.exp(model(img))\n",
    "# Make sure the shape is appropriate, we should get 10 class probabilities for 64 examples\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:09:06.432988Z",
     "start_time": "2019-02-04T13:09:06.341035Z"
    },
    "_uuid": "72a2ebdd77e3380b972e24e1565bc7744beedd27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_prob.shape,top_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:10:21.313112Z",
     "start_time": "2019-02-04T13:10:21.305216Z"
    },
    "_uuid": "9f6368720bf311e1ee9977f0f2562a02b1afc12f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 1, 1, 1, 1, 8, 1, 1, 1, 8, 1, 1, 8, 1, 1, 1, 8, 1, 8, 8, 2, 8, 1, 2,\n",
       "        8, 1, 8, 8, 8, 1, 1, 8, 8, 8, 1, 8, 1, 1, 1, 1, 8, 1, 1, 1, 1, 8, 8, 1,\n",
       "        2, 1, 1, 8, 1, 1, 8, 8, 8, 1, 1, 8, 1, 1, 8, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_class.view(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "a9a05d7571a12641d0da644ae00b1608346faf6a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Predicted  Actual\n",
       "0           1       7\n",
       "1           1       0\n",
       "2           1       4\n",
       "3           1       4\n",
       "4           1       4\n",
       "5           1       5\n",
       "6           1       3\n",
       "7           1       3\n",
       "8           1       3\n",
       "9           1       3\n",
       "10          1       9\n",
       "11          1       3\n",
       "12          1       4\n",
       "13          1       7\n",
       "14          1       8\n",
       "15          1       0\n",
       "16          1       7\n",
       "17          1       3\n",
       "18          1       3\n",
       "19          1       9\n",
       "20          1       8\n",
       "21          1       2\n",
       "22          1       1\n",
       "23          1       1\n",
       "24          1       4\n",
       "25          1       2\n",
       "26          1       8\n",
       "27          1       6\n",
       "28          1       5\n",
       "29          1       6\n",
       "..        ...     ...\n",
       "34          1       3\n",
       "35          1       0\n",
       "36          1       4\n",
       "37          1       7\n",
       "38          1       6\n",
       "39          1       6\n",
       "40          1       8\n",
       "41          1       6\n",
       "42          1       6\n",
       "43          1       5\n",
       "44          1       5\n",
       "45          1       3\n",
       "46          1       9\n",
       "47          1       3\n",
       "48          1       9\n",
       "49          1       1\n",
       "50          1       2\n",
       "51          1       3\n",
       "52          1       0\n",
       "53          1       5\n",
       "54          1       0\n",
       "55          1       4\n",
       "56          1       6\n",
       "57          1       7\n",
       "58          1       5\n",
       "59          1       3\n",
       "60          1       7\n",
       "61          1       6\n",
       "62          1       8\n",
       "63          1       0\n",
       "\n",
       "[64 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Predicted\":top_class.view(top_class.shape[0]),\"Actual\":labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "3f958e5da0aed9b404c743c8798b64e0d4341fdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046875"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equals=top_class == labels.view(*top_class.shape)\n",
    "accuracy=torch.mean(equals.type(torch.FloatTensor))\n",
    "accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:27:29.556056Z",
     "start_time": "2019-02-04T13:27:29.541115Z"
    },
    "_uuid": "352673a9d93a8f6b52165952364a7793ff43b8f0"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:29:20.825396Z",
     "start_time": "2019-02-04T13:27:30.220213Z"
    },
    "_uuid": "d7ef3898265ce167202ee321100129a95e3b748e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.405..  Test Loss: 0.216..  Test Accuracy: 0.945\n",
      "Epoch: 2/5..  Training Loss: 0.312..  Test Loss: 0.174..  Test Accuracy: 0.958\n",
      "Epoch: 3/5..  Training Loss: 0.283..  Test Loss: 0.190..  Test Accuracy: 0.957\n",
      "Epoch: 4/5..  Training Loss: 0.272..  Test Loss: 0.189..  Test Accuracy: 0.960\n",
      "Epoch: 5/5..  Training Loss: 0.272..  Test Loss: 0.165..  Test Accuracy: 0.963\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        #images=images.view(images.shape[0],-1)\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels) # a single value for ex 2.33\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.shape[0] ## (2.33*64 + 2.22*64 + 2.12*33) / 138 \n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in testloader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels) *images.shape[0]\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.sum(equals).item()\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(trainloader.dataset))\n",
    "        test_losses.append(test_loss.item()/len(testloader.dataset))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader.dataset)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader.dataset)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader.dataset)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:24:46.424543Z",
     "start_time": "2019-02-04T13:24:46.420315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114.80688328295946"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T13:13:40.841068Z",
     "start_time": "2019-02-04T13:13:40.833492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3])==torch.tensor([1,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "_uuid": "086d29056a5322e8c76820fcdc87ddc5424539ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f46085a94a8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 373
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5612d928a89de850888b2caa3251617ff1ebc9fc"
   },
   "source": [
    "## Inference time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_uuid": "e908e92d92cf3f2634fa665acbca4012bacdb3bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, tensor(0))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "top_prob,top_class=ps.topk(1,dim=1)\n",
    "top_class.item(),labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086a197d3e597422ee8b592832f811444577b876"
   },
   "source": [
    "The parameters for PyTorch networks are stored in a model's state_dict\n",
    " Optimizer objects (torch.optim) also have a state_dict, which contains information about the optimizerâ€™s state, as well as the hyperparameters used.\n",
    "\n",
    "Because state_dict objects are Python dictionaries, they can be easily saved, updated, altered, and restored, adding a great deal of modularity to PyTorch models and optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_uuid": "2dbde41ca47a505766ec29ad2c89443f9a4d8d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "fc1.weight \t torch.Size([256, 784])\n",
      "fc1.bias \t torch.Size([256])\n",
      "fc2.weight \t torch.Size([128, 256])\n",
      "fc2.bias \t torch.Size([128])\n",
      "fc3.weight \t torch.Size([64, 128])\n",
      "fc3.bias \t torch.Size([64])\n",
      "fc4.weight \t torch.Size([10, 64])\n",
      "fc4.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_uuid": "67e383a0385379d68f1c4f0d38143504b098a8d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer's state_dict:\n",
      "state \t {139938764448248: {'step': 4690, 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        ...,\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [-5.6052e-45, -5.6052e-45, -5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[1.0672e-12, 1.0672e-12, 1.0672e-12,  ..., 1.0672e-12, 1.0672e-12,\n",
      "         1.0672e-12],\n",
      "        [5.6438e-12, 5.6438e-12, 5.6438e-12,  ..., 5.6438e-12, 5.6438e-12,\n",
      "         5.6438e-12],\n",
      "        [2.6544e-12, 2.6544e-12, 2.6544e-12,  ..., 2.6544e-12, 2.6544e-12,\n",
      "         2.6544e-12],\n",
      "        ...,\n",
      "        [3.5010e-10, 3.5010e-10, 3.5010e-10,  ..., 3.5010e-10, 3.5010e-10,\n",
      "         3.5010e-10],\n",
      "        [2.6235e-13, 2.6235e-13, 2.6235e-13,  ..., 2.6235e-13, 2.6235e-13,\n",
      "         2.6235e-13],\n",
      "        [1.5348e-13, 1.5348e-13, 1.5348e-13,  ..., 1.5348e-13, 1.5348e-13,\n",
      "         1.5348e-13]])}, 139938764448320: {'step': 4690, 'exp_avg': tensor([ 5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  1.9869e-03,  5.6052e-45, -3.8861e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  4.1826e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -7.0754e-05,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  6.2205e-04,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45,  5.7664e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -7.6798e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -7.5801e-05,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -3.6247e-04,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  0.0000e+00,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -5.6052e-45,\n",
      "         5.6052e-45,  1.9959e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  8.9999e-05,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         4.8723e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -6.2868e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  3.2150e-04,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  1.3377e-03,\n",
      "         5.6052e-45,  0.0000e+00,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -1.2911e-04,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -2.5788e-03,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45, -2.2109e-05,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  2.3889e-04,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45]), 'exp_avg_sq': tensor([1.0672e-12, 5.6438e-12, 2.6544e-12, 1.7969e-10, 2.7641e-10, 1.1351e-10,\n",
      "        1.9261e-11, 2.6192e-05, 2.1720e-09, 1.5409e-05, 3.9248e-12, 1.6586e-12,\n",
      "        6.5444e-12, 1.1637e-09, 1.0256e-13, 2.6695e-09, 3.0330e-14, 1.1122e-14,\n",
      "        2.7887e-11, 6.3554e-10, 8.3343e-13, 2.4236e-10, 2.2410e-12, 1.2457e-12,\n",
      "        4.8346e-12, 2.4334e-13, 2.7988e-12, 9.8203e-10, 3.5959e-10, 1.3392e-09,\n",
      "        4.1938e-10, 3.2680e-11, 1.4212e-10, 9.3625e-12, 8.1192e-11, 3.6879e-14,\n",
      "        1.3181e-11, 5.7402e-13, 1.5562e-10, 2.0967e-13, 5.7243e-12, 3.0011e-12,\n",
      "        3.4388e-10, 3.7287e-10, 3.2670e-05, 4.5105e-12, 1.0419e-10, 1.1023e-06,\n",
      "        4.0710e-12, 1.1458e-11, 2.9676e-12, 6.2899e-10, 1.2500e-05, 2.8583e-11,\n",
      "        3.3725e-12, 6.4890e-13, 5.6665e-14, 4.1907e-11, 2.1881e-05, 5.2413e-10,\n",
      "        6.3047e-11, 4.0407e-10, 3.5480e-11, 5.2225e-10, 8.4388e-08, 3.6585e-10,\n",
      "        3.0677e-13, 4.5140e-12, 1.5527e-10, 2.2364e-13, 6.8517e-11, 2.2283e-10,\n",
      "        9.2202e-15, 6.9845e-12, 1.9735e-12, 1.7842e-11, 9.0682e-11, 1.3479e-10,\n",
      "        1.3722e-09, 3.8547e-12, 3.6745e-10, 3.9654e-11, 1.5636e-11, 9.7886e-14,\n",
      "        3.6133e-09, 2.3397e-13, 5.8986e-11, 4.6151e-11, 5.3210e-10, 1.8769e-11,\n",
      "        6.6370e-10, 0.0000e+00, 5.1186e-12, 1.1946e-10, 3.0534e-05, 2.6922e-10,\n",
      "        2.4455e-15, 1.4132e-14, 1.0190e-11, 1.8254e-14, 1.3637e-13, 4.0029e-12,\n",
      "        2.5329e-10, 1.0020e-10, 3.3058e-11, 3.9839e-12, 2.8040e-09, 1.0039e-09,\n",
      "        1.6956e-13, 2.6669e-05, 7.9699e-10, 3.6006e-12, 1.0587e-11, 1.1921e-12,\n",
      "        1.2113e-10, 1.5312e-12, 4.9272e-13, 4.5935e-13, 3.9149e-10, 1.9017e-09,\n",
      "        2.6293e-05, 1.6448e-09, 3.4819e-15, 7.5784e-10, 1.9334e-12, 9.3651e-12,\n",
      "        4.5913e-12, 1.7880e-15, 3.7740e-13, 1.0218e-09, 1.0727e-12, 6.4843e-12,\n",
      "        9.9876e-06, 4.4223e-12, 1.6688e-10, 1.9079e-11, 3.1336e-11, 7.8380e-14,\n",
      "        1.4823e-12, 2.5071e-10, 5.0848e-12, 1.4520e-09, 4.9023e-10, 2.5450e-05,\n",
      "        5.5733e-13, 1.3309e-09, 1.3828e-11, 1.2068e-14, 2.2570e-13, 0.0000e+00,\n",
      "        2.8853e-13, 1.6869e-10, 2.1133e-11, 1.2078e-11, 1.5241e-07, 7.1458e-13,\n",
      "        1.9263e-05, 4.2083e-14, 1.2893e-14, 1.0257e-10, 8.3892e-10, 4.5716e-05,\n",
      "        7.1241e-10, 6.0215e-10, 2.3477e-12, 2.3442e-05, 9.6258e-13, 1.2284e-13,\n",
      "        2.7751e-10, 5.3265e-11, 1.3688e-10, 3.5399e-05, 8.4617e-13, 3.0231e-13,\n",
      "        2.9974e-13, 3.0907e-10, 8.6281e-10, 1.9042e-05, 1.0379e-09, 4.4594e-11,\n",
      "        1.7976e-09, 1.2312e-09, 1.2393e-09, 9.4911e-10, 6.4908e-13, 3.2711e-10,\n",
      "        1.9321e-12, 2.7228e-11, 1.3660e-08, 4.6847e-05, 6.4379e-11, 0.0000e+00,\n",
      "        5.7597e-10, 1.1104e-09, 1.8395e-09, 7.4474e-11, 9.9066e-11, 3.4771e-12,\n",
      "        1.1544e-05, 2.4175e-10, 3.6509e-13, 4.4882e-10, 1.3791e-12, 6.2391e-10,\n",
      "        3.0720e-13, 1.0717e-09, 5.0825e-13, 1.5498e-11, 2.1542e-11, 1.1633e-12,\n",
      "        1.3219e-12, 4.4117e-10, 2.6094e-13, 3.8293e-05, 1.0151e-12, 1.0421e-11,\n",
      "        4.7784e-11, 1.7600e-09, 1.0329e-09, 3.4237e-10, 8.7960e-15, 4.2933e-12,\n",
      "        2.6447e-10, 9.7544e-12, 9.1105e-11, 4.7322e-10, 2.9594e-10, 2.6980e-10,\n",
      "        7.2375e-10, 2.7878e-06, 1.5102e-11, 6.6121e-13, 3.8656e-10, 4.6128e-12,\n",
      "        3.3457e-14, 7.4658e-13, 2.9440e-12, 3.8289e-10, 1.0048e-12, 4.0302e-11,\n",
      "        1.9687e-11, 1.9553e-09, 2.1182e-05, 9.2287e-10, 6.6251e-11, 2.6063e-12,\n",
      "        2.6851e-12, 2.4373e-12, 1.8735e-13, 6.1066e-10, 4.6465e-11, 2.7108e-11,\n",
      "        2.0267e-08, 3.5010e-10, 2.6235e-13, 1.5348e-13])}, 139938764448032: {'step': 4690, 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.6052e-45,  0.0000e+00],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  0.0000e+00],\n",
      "        [-5.6052e-45,  5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45,  0.0000e+00],\n",
      "        ...,\n",
      "        [-5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -5.6052e-45, -5.6052e-45],\n",
      "        [ 5.6052e-45,  5.6052e-45, -5.6052e-45,  ...,  5.6052e-45,\n",
      "          5.6052e-45, -5.6052e-45]]), 'exp_avg_sq': tensor([[7.9434e-14, 1.0418e-11, 1.5213e-12,  ..., 7.2758e-08, 3.2244e-14,\n",
      "         0.0000e+00],\n",
      "        [9.8376e-12, 2.8354e-12, 1.0845e-10,  ..., 4.5710e-14, 4.4737e-12,\n",
      "         0.0000e+00],\n",
      "        [8.4480e-12, 9.1435e-12, 3.7939e-12,  ..., 1.6609e-07, 1.0777e-13,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [1.0025e-12, 3.7958e-13, 4.0860e-14,  ..., 2.7594e-10, 2.1368e-15,\n",
      "         7.2536e-16],\n",
      "        [3.5580e-12, 1.0942e-11, 3.1708e-12,  ..., 8.5364e-14, 1.7037e-13,\n",
      "         7.6908e-18],\n",
      "        [1.8645e-12, 5.9150e-13, 4.0718e-14,  ..., 4.5469e-15, 4.1382e-14,\n",
      "         9.2481e-15]])}, 139938764448392: {'step': 4690, 'exp_avg': tensor([ 5.6052e-45, -7.1913e-04,  5.6052e-45,  1.3756e-03,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45, -1.0154e-03,  1.0552e-05, -6.8788e-04,\n",
      "         1.3395e-04, -4.4091e-04,  5.6052e-45,  5.6052e-45, -4.5439e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45, -2.3769e-04, -3.4736e-05,\n",
      "         2.4078e-04,  5.6052e-45, -1.7613e-05, -4.7469e-05, -7.3205e-06,\n",
      "        -6.2514e-05,  5.6052e-45, -6.4710e-04, -3.3509e-04,  5.1641e-05,\n",
      "         5.6052e-45,  2.5371e-03,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "        -3.3937e-04, -7.6775e-04,  5.6052e-45, -1.1263e-03, -1.0148e-04,\n",
      "        -8.7690e-05,  5.6052e-45,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         2.2413e-04, -6.3344e-04,  1.9339e-03,  5.6052e-45,  5.6052e-45,\n",
      "        -1.5525e-03,  6.6449e-04,  5.6052e-45,  5.2412e-29, -5.6052e-45,\n",
      "        -2.1826e-04,  6.7769e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         3.2539e-04,  5.6052e-45,  5.8819e-04, -5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  5.6052e-45,  1.1595e-05, -1.8346e-04,  5.6052e-45,\n",
      "         5.6052e-45,  1.6366e-03,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         7.1367e-04, -6.8712e-04,  5.6052e-45,  5.6052e-45,  1.3969e-16,\n",
      "        -3.0182e-03,  5.6052e-45, -3.8315e-06,  5.6052e-45,  3.5855e-04,\n",
      "         7.1612e-07,  5.6052e-45, -1.2283e-03, -1.4189e-03,  5.6052e-45,\n",
      "        -3.3793e-04,  5.6052e-45,  3.6493e-05, -1.1643e-03,  9.2152e-04,\n",
      "         2.1364e-03,  5.6052e-45,  5.6052e-45, -2.8686e-03,  4.3256e-03,\n",
      "        -2.5910e-04,  5.6052e-45, -9.8143e-05,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45, -3.7262e-04,  5.6052e-45,  5.6052e-45,  5.6052e-45,\n",
      "         5.6052e-45,  1.8485e-04,  5.6052e-45,  5.6052e-45,  4.7573e-04,\n",
      "         5.6052e-45,  5.6052e-45,  5.6052e-45,  1.8171e-04,  5.6052e-45,\n",
      "         5.6052e-45, -7.0720e-19,  8.2645e-04,  5.6052e-45,  2.4895e-07,\n",
      "         5.6052e-45,  4.4287e-04,  5.6052e-45]), 'exp_avg_sq': tensor([3.0625e-09, 3.7561e-05, 9.0181e-09, 8.0511e-06, 1.8948e-08, 3.7467e-09,\n",
      "        1.2617e-10, 2.0565e-05, 2.9852e-06, 1.6851e-05, 6.0831e-05, 4.5191e-05,\n",
      "        6.3829e-12, 2.3772e-09, 3.5977e-05, 6.1131e-09, 1.2825e-07, 8.2513e-08,\n",
      "        1.7493e-05, 7.2988e-07, 4.2514e-05, 1.1519e-07, 1.6583e-05, 9.4784e-05,\n",
      "        6.7253e-06, 1.5528e-05, 6.4440e-11, 4.6124e-05, 1.0704e-05, 4.5202e-06,\n",
      "        5.8952e-08, 1.4539e-05, 9.4094e-10, 3.7332e-08, 4.1061e-09, 3.8045e-05,\n",
      "        1.6538e-05, 1.7228e-07, 4.6733e-05, 1.9921e-05, 3.6860e-06, 1.5960e-09,\n",
      "        6.5657e-11, 5.7696e-10, 9.0410e-08, 1.6904e-05, 3.7576e-06, 3.6612e-05,\n",
      "        2.6237e-11, 1.9321e-06, 4.3232e-05, 8.2078e-06, 6.0868e-10, 8.0649e-07,\n",
      "        2.6894e-09, 2.8251e-05, 5.2627e-05, 5.9598e-07, 1.1437e-10, 1.2803e-09,\n",
      "        2.1045e-05, 1.1579e-09, 7.0277e-06, 1.7403e-08, 2.7567e-10, 1.5016e-07,\n",
      "        3.2373e-07, 1.6453e-05, 4.5019e-06, 1.3831e-09, 1.2823e-09, 4.7300e-05,\n",
      "        1.3828e-07, 1.9206e-11, 2.4236e-09, 2.6732e-05, 3.1049e-05, 9.5279e-09,\n",
      "        3.8238e-10, 1.3876e-05, 2.4552e-05, 6.3225e-10, 2.4355e-06, 6.5541e-10,\n",
      "        6.8401e-06, 4.3883e-06, 3.7382e-09, 3.9870e-05, 2.3104e-05, 5.0632e-09,\n",
      "        9.3330e-06, 2.0109e-06, 1.5914e-05, 1.7909e-05, 2.8939e-06, 3.4523e-05,\n",
      "        6.7039e-11, 3.0427e-09, 3.1710e-05, 8.4305e-05, 3.2208e-05, 1.4317e-11,\n",
      "        7.8699e-06, 1.9220e-09, 8.8705e-09, 8.2019e-09, 1.3335e-05, 1.0542e-09,\n",
      "        3.9586e-09, 1.4460e-08, 2.3743e-10, 3.4270e-05, 3.4869e-07, 1.1575e-09,\n",
      "        2.7310e-05, 9.3249e-10, 3.4640e-07, 7.7720e-09, 5.9898e-05, 1.4325e-09,\n",
      "        2.3490e-10, 2.1520e-07, 1.4228e-05, 6.5757e-09, 6.3056e-06, 1.2339e-08,\n",
      "        4.7670e-06, 8.2343e-11])}, 139938764448464: {'step': 4690, 'exp_avg': tensor([[-5.6052e-45, -5.6052e-45,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -6.2412e-21, -5.6052e-45],\n",
      "        [-5.6052e-45, -1.3829e-09, -5.6052e-45,  ...,  5.6052e-45,\n",
      "         -1.0002e-29,  5.6052e-45],\n",
      "        [ 5.6052e-45,  4.9096e-14,  5.6052e-45,  ..., -5.6052e-45,\n",
      "          1.2612e-44,  5.6052e-45],\n",
      "        ...,\n",
      "        [-5.6052e-45,  6.2319e-05,  5.6052e-45,  ...,  5.6052e-45,\n",
      "          3.3463e-03,  5.6052e-45],\n",
      "        [ 5.6052e-45, -2.6765e-09,  5.6052e-45,  ...,  5.6052e-45,\n",
      "         -5.2536e-07, -5.6052e-45],\n",
      "        [ 5.6052e-45, -7.3111e-04,  5.6052e-45,  ..., -5.6052e-45,\n",
      "         -3.2900e-07, -5.6052e-45]]), 'exp_avg_sq': tensor([[4.1102e-10, 7.6559e-08, 2.9449e-10,  ..., 4.6118e-11, 2.4881e-07,\n",
      "         6.2620e-12],\n",
      "        [1.3446e-11, 1.3998e-07, 8.1897e-12,  ..., 4.1310e-10, 1.0512e-07,\n",
      "         2.3035e-11],\n",
      "        [5.2659e-07, 1.6210e-05, 1.7766e-07,  ..., 4.7629e-10, 6.1656e-07,\n",
      "         3.6837e-11],\n",
      "        ...,\n",
      "        [4.4067e-07, 2.9003e-04, 7.1843e-08,  ..., 3.5204e-08, 3.4335e-04,\n",
      "         2.7386e-11],\n",
      "        [1.4739e-07, 3.0986e-07, 8.9177e-08,  ..., 1.0348e-09, 4.7723e-07,\n",
      "         1.5658e-11],\n",
      "        [1.2048e-09, 5.9770e-04, 5.5027e-09,  ..., 1.0889e-08, 5.9129e-05,\n",
      "         1.0608e-12]])}, 139938764448536: {'step': 4690, 'exp_avg': tensor([-1.2694e-03, -2.6088e-04, -1.2199e-04, -2.7442e-03,  3.3557e-29,\n",
      "         1.2621e-03,  1.3546e-03, -1.0149e-05, -1.2716e-04,  1.0449e-03,\n",
      "         9.9274e-05,  6.9325e-19, -1.7420e-03,  5.2731e-04,  2.2307e-03,\n",
      "        -9.7052e-04,  1.9915e-04,  8.6799e-04,  8.5638e-04,  3.1660e-09,\n",
      "         1.7964e-03,  1.5173e-03,  1.2052e-03,  2.5808e-10, -4.4369e-08,\n",
      "         1.1477e-04,  3.6653e-05,  6.0222e-05,  1.1924e-03, -1.6580e-04,\n",
      "         1.1767e-04,  6.2779e-09, -4.1949e-06,  2.0211e-19, -1.4377e-03,\n",
      "        -7.9575e-05,  1.3026e-04, -3.3452e-04, -1.3891e-06, -1.9050e-03,\n",
      "        -3.8414e-05,  6.3988e-04,  3.1106e-03,  1.7934e-03, -2.4263e-03,\n",
      "        -8.7117e-04,  8.9961e-08,  1.3902e-03,  3.8136e-07, -3.1852e-04,\n",
      "         1.8891e-04,  1.9144e-03,  4.4033e-05,  1.7421e-03, -1.3275e-03,\n",
      "        -1.8738e-04, -5.0274e-04, -1.1329e-03,  1.1579e-03,  5.6052e-45,\n",
      "         1.1028e-03, -1.2924e-03, -1.1409e-03,  1.1723e-04]), 'exp_avg_sq': tensor([2.6705e-06, 1.1447e-05, 7.2141e-06, 3.1170e-05, 3.2152e-07, 8.5145e-05,\n",
      "        2.4227e-05, 1.1884e-06, 8.7847e-07, 2.8445e-05, 4.9708e-06, 7.0964e-07,\n",
      "        2.1961e-05, 1.7090e-05, 4.1470e-05, 5.5243e-05, 6.5839e-06, 1.2135e-05,\n",
      "        2.7767e-05, 4.6554e-07, 3.3138e-05, 3.2179e-05, 4.9872e-05, 2.5243e-07,\n",
      "        1.0274e-07, 2.8582e-05, 1.9342e-05, 2.9582e-05, 1.7365e-05, 9.5685e-06,\n",
      "        3.1398e-05, 1.1863e-06, 9.3599e-07, 3.4258e-07, 1.5000e-05, 4.0506e-05,\n",
      "        1.8539e-05, 1.0701e-05, 1.6539e-06, 1.3089e-05, 2.4012e-05, 1.4182e-05,\n",
      "        2.7168e-05, 3.8256e-05, 1.8248e-05, 4.0793e-05, 5.2570e-07, 6.6052e-05,\n",
      "        2.4673e-05, 2.2549e-06, 1.5263e-06, 3.7395e-05, 1.6370e-05, 3.2275e-05,\n",
      "        2.3170e-05, 1.0391e-06, 4.0327e-05, 2.7588e-05, 8.9917e-05, 7.6201e-09,\n",
      "        1.6539e-06, 2.2187e-05, 1.9825e-05, 3.7704e-05])}, 139938764448608: {'step': 4690, 'exp_avg': tensor([[ 4.2187e-05,  2.6604e-04, -1.3696e-03,  4.9864e-03, -1.7112e-29,\n",
      "          1.9029e-03,  5.2715e-04, -2.3401e-05,  3.9151e-06,  6.7277e-04,\n",
      "          7.4782e-03,  8.1841e-20,  6.3295e-04, -8.9461e-05,  1.4987e-03,\n",
      "          2.5820e-03,  1.3190e-04,  2.0128e-03,  7.1884e-04,  1.7423e-12,\n",
      "          2.1116e-02,  2.9078e-03,  2.0028e-03, -1.5851e-10,  2.6016e-09,\n",
      "          1.6087e-03,  2.5039e-03,  1.1108e-03,  1.6185e-04,  1.1327e-04,\n",
      "          7.1695e-04,  1.8841e-10, -4.6761e-05,  5.9265e-20,  1.9123e-04,\n",
      "          1.2160e-03,  9.9651e-04,  2.3551e-03, -2.5064e-06,  6.0944e-04,\n",
      "          3.2372e-04,  9.0761e-04,  1.7688e-03,  7.7591e-03,  3.7219e-03,\n",
      "          1.0351e-03,  4.7072e-10,  1.8399e-03,  2.6266e-03,  1.2512e-06,\n",
      "          5.1762e-07,  6.4767e-04,  2.6818e-04,  8.1789e-04,  4.2889e-03,\n",
      "         -7.9262e-07,  5.4598e-03,  7.5546e-04,  1.1576e-03,  5.6052e-45,\n",
      "          4.7542e-04,  5.8726e-04,  9.2837e-04,  5.2679e-04],\n",
      "        [-3.3542e-03, -3.6314e-04, -1.2586e-04,  1.0465e-03,  1.5351e-29,\n",
      "         -2.1748e-04, -2.8837e-04,  2.4769e-06,  2.5729e-05,  2.0451e-04,\n",
      "         -1.7791e-05,  3.1593e-20,  3.7534e-03, -1.7797e-03, -5.2851e-03,\n",
      "          4.1384e-03,  1.0063e-05,  2.5123e-04, -7.7640e-03,  8.3253e-13,\n",
      "          8.1167e-04,  4.0520e-04,  1.8341e-03,  9.3560e-13,  3.3592e-07,\n",
      "          1.2315e-03,  2.2896e-03,  2.6526e-03,  3.5277e-04,  4.5061e-05,\n",
      "         -4.7379e-03,  2.3253e-12,  5.1016e-08,  1.4028e-20, -9.6820e-04,\n",
      "         -7.2170e-03, -6.2380e-05,  8.8532e-04,  8.6003e-10, -4.6996e-03,\n",
      "         -4.1461e-04,  5.5056e-04, -7.2071e-03, -1.3774e-03,  1.3818e-03,\n",
      "          9.5002e-04,  2.5075e-10,  1.4318e-03, -1.3602e-03, -1.2410e-04,\n",
      "         -4.8825e-04, -5.7250e-03, -2.1955e-04, -1.7338e-03,  2.3564e-04,\n",
      "          2.4592e-05, -7.0211e-04, -3.5459e-05,  5.0628e-04,  5.6052e-45,\n",
      "         -1.5265e-03,  1.5642e-04, -1.2340e-03,  7.4013e-04],\n",
      "        [ 2.1434e-03,  4.5749e-04,  3.3681e-04,  8.9392e-03,  7.3956e-31,\n",
      "         -2.0396e-03, -2.7319e-03,  2.0980e-05,  2.0359e-05,  4.3048e-04,\n",
      "          5.9199e-04,  6.6045e-20,  2.4231e-03,  4.0255e-03,  3.2932e-02,\n",
      "          8.6814e-03,  2.2720e-03,  6.5535e-03,  9.4804e-03,  2.2633e-09,\n",
      "          4.1272e-03,  2.6908e-03,  4.9730e-03,  1.0601e-11,  2.0770e-07,\n",
      "          4.9314e-03,  2.8137e-02,  1.3110e-02,  2.9057e-02,  9.7522e-04,\n",
      "          7.6791e-03,  6.0080e-11,  3.7882e-05,  7.2717e-18,  1.1034e-03,\n",
      "          3.8246e-03,  3.4990e-03,  7.6195e-04,  7.2009e-07,  2.9840e-03,\n",
      "          5.3754e-03, -4.9280e-04,  9.1907e-03,  3.6835e-03,  3.3507e-03,\n",
      "          2.1576e-06,  8.1283e-10,  2.4717e-03, -2.4314e-03,  1.5895e-04,\n",
      "          4.1714e-04,  9.3145e-03,  9.6410e-04,  1.0803e-02,  2.1461e-02,\n",
      "          2.3276e-04,  3.3825e-03, -1.8260e-03, -2.4202e-03,  5.6052e-45,\n",
      "          4.1496e-03, -1.8345e-03,  1.0932e-02,  1.5034e-03],\n",
      "        [-1.8528e-03,  3.6868e-04,  4.8061e-04, -5.1192e-03, -7.8215e-29,\n",
      "          1.1526e-03, -2.9197e-03,  2.7166e-06,  3.6338e-05, -7.2724e-03,\n",
      "          5.1178e-04,  1.9198e-19,  1.5576e-03, -2.4770e-04, -1.9984e-02,\n",
      "         -3.6837e-03,  1.4203e-04, -4.5522e-03,  3.4927e-03,  2.8758e-12,\n",
      "          1.5391e-02, -1.7772e-03, -5.7509e-03,  3.5008e-11, -8.9722e-07,\n",
      "         -3.3415e-03, -7.0807e-03, -2.9294e-02, -2.0003e-02,  5.8361e-04,\n",
      "          3.1023e-03, -2.8464e-07,  7.0937e-07,  7.2191e-18,  8.2473e-04,\n",
      "          2.9577e-03,  1.7735e-03,  7.1002e-04,  2.0628e-07,  1.6079e-03,\n",
      "          1.2529e-03, -1.8871e-03, -2.3552e-03, -6.3152e-03,  1.7635e-03,\n",
      "          4.3763e-03,  1.4073e-09, -1.2899e-02,  1.8266e-03, -1.1865e-03,\n",
      "          2.8877e-05,  5.1754e-04,  2.1931e-04, -2.8071e-03, -1.3508e-02,\n",
      "         -3.9310e-03, -1.5481e-03,  2.3059e-04, -4.4032e-04, -5.6052e-45,\n",
      "         -1.9305e-02,  1.0420e-03, -1.6216e-02,  2.8147e-03],\n",
      "        [ 1.7235e-04, -1.7584e-04, -1.6904e-05, -8.5751e-03,  1.1478e-31,\n",
      "         -2.8169e-03, -3.3283e-03,  2.9893e-06,  1.0040e-04,  2.3429e-03,\n",
      "          3.2027e-04,  9.9320e-20, -1.2071e-02,  1.1296e-03, -8.9843e-03,\n",
      "         -4.6642e-03,  5.5587e-03,  3.3427e-04, -1.0583e-02, -4.6654e-09,\n",
      "         -4.0574e-03,  1.6450e-05, -3.1495e-02,  6.3359e-12,  6.2557e-10,\n",
      "          3.5299e-03, -1.4307e-02, -3.9670e-03,  3.6267e-04,  2.0332e-04,\n",
      "         -1.2003e-02,  4.1124e-11,  1.1215e-06,  1.1167e-21,  2.0489e-04,\n",
      "         -3.2243e-02, -1.5986e-03,  2.2387e-03,  2.6648e-08,  7.8832e-05,\n",
      "         -1.5170e-02, -3.7002e-03, -9.3753e-05, -8.2324e-04,  4.1171e-04,\n",
      "         -4.6575e-02,  3.1692e-08, -5.4948e-03, -2.8384e-03,  5.4727e-05,\n",
      "          3.6916e-06, -5.8607e-03,  1.8189e-02, -1.1772e-02, -4.7710e-03,\n",
      "          9.5761e-08, -1.4206e-04,  1.2007e-02, -3.1590e-03,  5.6052e-45,\n",
      "         -3.1731e-03,  3.9314e-03, -3.6387e-03, -9.0185e-05],\n",
      "        [ 2.6565e-03,  4.0214e-04, -7.2051e-05,  2.8062e-03,  7.7458e-29,\n",
      "         -6.5250e-04,  1.8336e-03, -1.4513e-05,  1.0764e-05, -9.1864e-04,\n",
      "          4.7937e-04, -8.0273e-19, -6.9907e-04, -1.6974e-03, -1.0601e-02,\n",
      "          4.2446e-04, -7.3027e-03, -1.6737e-03, -1.2562e-03,  7.5716e-11,\n",
      "         -2.8671e-02, -2.4980e-03,  6.2782e-03,  4.3258e-11,  1.2327e-07,\n",
      "         -4.9683e-04, -5.7727e-03,  1.6668e-02, -1.4866e-02,  2.7199e-04,\n",
      "         -2.2523e-03,  3.7639e-11,  2.1353e-06,  1.7547e-19,  3.9535e-04,\n",
      "          5.5373e-04, -2.8453e-04,  7.9367e-04,  2.5573e-07,  1.0797e-03,\n",
      "         -1.6025e-03,  1.7226e-03, -4.0876e-03,  6.9553e-03,  5.5377e-03,\n",
      "          1.3147e-03,  3.3806e-09,  6.5330e-03, -1.0541e-03,  9.9492e-04,\n",
      "          1.3157e-06, -8.3144e-04, -3.2759e-04,  1.0302e-03, -6.1528e-03,\n",
      "          3.4976e-03,  6.5879e-03,  1.3895e-03,  2.4253e-03,  5.6052e-45,\n",
      "          1.8945e-02,  5.8229e-04,  1.3690e-02,  2.3418e-05],\n",
      "        [-2.5989e-04, -2.0477e-03,  3.5936e-04, -1.1176e-02,  1.2803e-30,\n",
      "         -5.6811e-04,  1.3798e-05,  1.8071e-06,  1.4188e-06, -4.5631e-04,\n",
      "         -3.5439e-03,  1.0497e-19, -9.4282e-04, -3.8251e-04,  4.8304e-03,\n",
      "          1.3663e-03,  8.4795e-03, -1.6011e-03,  7.4922e-04,  1.9273e-09,\n",
      "         -3.1722e-03, -2.4984e-03, -1.2202e-03,  1.2138e-11,  1.8087e-10,\n",
      "         -1.1085e-02, -3.9690e-03, -1.0470e-03,  8.6844e-04,  1.1566e-03,\n",
      "         -3.2268e-04,  3.9250e-11,  1.4322e-06,  1.0944e-22, -1.7118e-03,\n",
      "         -2.9426e-03, -9.3638e-04,  9.2713e-05,  3.4617e-07, -4.7432e-03,\n",
      "          8.0696e-04,  9.9422e-05, -6.1617e-03,  4.7998e-04, -2.2151e-02,\n",
      "         -2.7853e-03,  5.5539e-10,  1.5012e-03,  1.7151e-03,  2.8639e-06,\n",
      "          6.4770e-06, -1.0184e-03, -6.4777e-03, -4.0793e-03, -5.8255e-03,\n",
      "          2.7091e-07, -4.1333e-03, -7.8449e-03,  7.8116e-04,  5.6052e-45,\n",
      "          2.1154e-04, -1.3857e-04,  2.6875e-04, -5.9623e-04],\n",
      "        [ 2.7871e-04,  5.0526e-04,  1.0888e-04,  1.6472e-03,  1.9279e-31,\n",
      "          1.1461e-03,  2.8544e-03, -6.7834e-05,  7.4633e-05,  2.1030e-02,\n",
      "          4.0587e-04,  5.9754e-20,  1.5222e-03,  8.4653e-03,  3.9053e-03,\n",
      "          1.6968e-03, -9.4106e-03,  4.8177e-04,  3.6705e-03,  2.2261e-11,\n",
      "          3.8753e-03, -2.6566e-03,  2.7575e-02,  1.8432e-11,  9.8482e-08,\n",
      "          2.8061e-03, -6.6835e-03,  8.4084e-04,  1.1431e-03, -9.6757e-04,\n",
      "          2.9601e-03,  2.0254e-07,  2.0740e-06, -1.4760e-17,  6.0227e-04,\n",
      "          1.0782e-02, -7.8397e-03, -3.5276e-03,  2.2876e-07, -1.7897e-04,\n",
      "          5.3194e-03,  1.8559e-03,  5.1801e-03, -2.0267e-03,  1.6155e-05,\n",
      "          6.1034e-03, -1.0208e-07,  8.6650e-04,  1.7652e-03,  6.7847e-05,\n",
      "          1.9505e-05, -4.8422e-04, -2.5172e-03,  7.8138e-03,  3.2107e-04,\n",
      "          1.5823e-04,  2.4303e-03,  5.9023e-04,  7.2540e-04,  5.6052e-45,\n",
      "          5.0805e-04, -8.9785e-05,  8.5664e-04, -1.1661e-02],\n",
      "        [ 2.2742e-04,  3.8786e-04,  1.5409e-04,  2.7231e-03,  1.5587e-32,\n",
      "          1.8539e-03,  3.1528e-03,  3.6302e-06,  3.0286e-05, -1.1336e-02,\n",
      "         -7.5908e-03,  1.0348e-19,  2.3551e-03,  2.0570e-03,  2.7650e-03,\n",
      "         -8.3763e-03,  8.3492e-05, -2.8526e-03,  2.0590e-03,  1.5670e-13,\n",
      "         -1.2165e-02,  1.9710e-03, -1.4280e-02,  7.2332e-12,  2.7520e-08,\n",
      "          3.0460e-03,  1.8374e-03,  3.2059e-03,  3.0098e-03, -2.5274e-03,\n",
      "          4.0717e-03,  2.1743e-11,  1.9299e-07,  1.4547e-21, -1.0289e-03,\n",
      "          1.1407e-03,  8.0659e-04,  3.8781e-04,  9.7354e-08,  2.2146e-03,\n",
      "          3.6262e-03,  7.0616e-04,  4.0699e-03, -4.6725e-03,  3.3164e-03,\n",
      "          1.5301e-03,  1.2151e-09,  4.5305e-03, -1.8262e-03,  1.0010e-05,\n",
      "          9.6836e-06,  3.1652e-03,  4.2519e-04,  4.5566e-03,  2.9541e-03,\n",
      "          4.8607e-06, -6.2740e-03,  8.0440e-04,  2.5020e-03,  5.6052e-45,\n",
      "          5.5837e-04,  1.1359e-03, -6.1988e-03,  9.3863e-04],\n",
      "        [-5.3688e-05,  1.9922e-04,  1.4470e-04,  2.7213e-03,  1.1635e-32,\n",
      "          2.3914e-04,  8.8667e-04,  7.1143e-05, -3.0384e-04, -4.6974e-03,\n",
      "          1.3650e-03,  6.3746e-20,  1.4686e-03, -1.1481e-02, -1.0770e-03,\n",
      "         -2.1650e-03,  3.5494e-05,  1.0461e-03, -5.6768e-04,  3.7119e-10,\n",
      "          2.7446e-03,  1.4389e-03,  1.0083e-02,  9.3071e-11,  1.0098e-07,\n",
      "         -2.2298e-03,  3.0451e-03, -3.2803e-03, -8.6808e-05,  1.4581e-04,\n",
      "          7.8564e-04,  8.1706e-08,  1.1659e-06,  1.8233e-20,  3.8704e-04,\n",
      "          2.1928e-02,  3.6460e-03, -4.6978e-03,  6.2464e-07,  1.0473e-03,\n",
      "          4.8239e-04,  2.3789e-04, -3.0410e-04, -3.6629e-03,  2.6507e-03,\n",
      "          3.4049e-02,  6.2293e-08, -7.8084e-04,  1.5769e-03,  2.0067e-05,\n",
      "          1.0421e-06,  2.7491e-04, -1.0524e-02, -4.6289e-03,  9.9575e-04,\n",
      "          1.3345e-05, -5.0609e-03, -6.0704e-03, -2.0782e-03,  5.6052e-45,\n",
      "         -8.4293e-04, -5.3723e-03,  6.1220e-04,  5.8004e-03]]), 'exp_avg_sq': tensor([[2.1883e-07, 1.6201e-05, 1.8958e-03, 1.4396e-03, 2.7279e-05, 6.7022e-04,\n",
      "         2.3353e-04, 7.8067e-05, 1.3287e-06, 5.7056e-05, 1.3278e-03, 2.9265e-06,\n",
      "         1.8967e-05, 7.9478e-05, 2.2681e-04, 2.5733e-04, 3.1245e-04, 1.7981e-03,\n",
      "         8.7399e-04, 1.5764e-06, 3.6113e-03, 5.6667e-03, 7.8409e-05, 5.4610e-05,\n",
      "         5.8497e-07, 1.5129e-04, 6.5978e-04, 8.8302e-05, 1.8075e-03, 1.8133e-05,\n",
      "         3.2921e-05, 1.2176e-06, 2.2422e-04, 1.0524e-05, 2.5766e-05, 7.3899e-05,\n",
      "         2.4203e-03, 1.4351e-04, 9.6987e-04, 8.9928e-05, 9.0379e-05, 8.3479e-04,\n",
      "         1.4924e-04, 5.0731e-03, 1.0961e-03, 6.0364e-05, 7.0784e-06, 2.7753e-04,\n",
      "         2.3630e-05, 1.4073e-04, 9.0809e-06, 3.6693e-05, 8.5705e-05, 9.5203e-05,\n",
      "         2.3112e-03, 3.7333e-06, 1.4568e-03, 2.6249e-04, 1.0183e-04, 2.4988e-09,\n",
      "         9.5163e-05, 1.4432e-04, 5.0964e-05, 4.8801e-05],\n",
      "        [2.4048e-04, 3.1028e-04, 2.7713e-05, 2.5750e-04, 3.2501e-07, 1.6522e-04,\n",
      "         1.1347e-03, 1.0616e-06, 1.5650e-06, 5.7413e-04, 1.8202e-05, 4.1395e-05,\n",
      "         1.7319e-03, 3.3016e-04, 5.4576e-04, 5.3653e-04, 4.3326e-05, 9.4813e-06,\n",
      "         9.6826e-04, 2.0495e-05, 7.6988e-05, 1.0435e-04, 1.2653e-04, 1.6680e-07,\n",
      "         1.0058e-06, 2.6033e-04, 2.0332e-03, 4.0074e-03, 1.1766e-04, 3.3264e-05,\n",
      "         3.1315e-03, 1.5847e-06, 4.1382e-06, 7.7828e-07, 1.7058e-04, 1.4049e-03,\n",
      "         5.7828e-05, 1.1395e-04, 1.4821e-06, 5.9042e-04, 3.3081e-03, 1.8140e-04,\n",
      "         4.4278e-04, 1.0983e-04, 1.1669e-04, 7.4690e-05, 2.6807e-06, 9.8761e-04,\n",
      "         3.9516e-04, 1.7912e-04, 8.8512e-05, 2.1097e-03, 3.1417e-05, 2.6026e-03,\n",
      "         4.5248e-05, 2.8926e-05, 6.7529e-04, 3.8187e-05, 2.4044e-04, 1.5909e-10,\n",
      "         2.4393e-05, 4.1368e-05, 9.5813e-04, 4.8991e-04],\n",
      "        [2.3655e-04, 2.9506e-04, 3.4635e-04, 3.4303e-03, 1.5792e-05, 3.1341e-04,\n",
      "         5.1791e-03, 9.9411e-06, 7.5563e-06, 9.0502e-04, 1.6560e-04, 5.6657e-05,\n",
      "         5.2367e-04, 1.2643e-03, 6.0990e-03, 5.2554e-04, 1.3155e-03, 4.8623e-04,\n",
      "         4.3162e-03, 6.1900e-05, 2.4950e-04, 6.6816e-04, 4.6569e-04, 4.1045e-06,\n",
      "         6.3059e-06, 3.2749e-03, 1.8341e-03, 1.6312e-03, 2.0322e-03, 7.7112e-04,\n",
      "         1.5096e-03, 8.4134e-06, 7.1783e-05, 5.7326e-06, 2.0501e-04, 6.9166e-04,\n",
      "         6.6931e-04, 1.1693e-03, 1.4508e-04, 1.8956e-04, 9.0558e-04, 2.3381e-03,\n",
      "         6.6214e-03, 1.7782e-04, 3.3667e-03, 2.8070e-04, 2.2509e-05, 2.9269e-03,\n",
      "         2.8544e-04, 1.0033e-04, 2.6134e-04, 3.3836e-03, 1.1883e-03, 5.5677e-03,\n",
      "         2.3527e-03, 1.5459e-04, 3.4185e-04, 1.5266e-03, 2.3956e-04, 1.5240e-10,\n",
      "         2.0902e-04, 1.1801e-03, 1.6187e-03, 4.8698e-04],\n",
      "        [4.5851e-05, 7.8271e-05, 1.8265e-04, 5.1994e-04, 7.5082e-06, 3.9947e-04,\n",
      "         1.5695e-03, 5.4561e-06, 1.3177e-05, 2.2902e-03, 1.1702e-04, 1.2063e-05,\n",
      "         1.5546e-04, 7.7580e-04, 7.4048e-03, 3.5775e-03, 1.5215e-04, 2.1205e-04,\n",
      "         1.8141e-03, 2.6420e-05, 2.9814e-03, 1.0827e-03, 1.0492e-03, 2.8220e-06,\n",
      "         1.5481e-05, 6.7187e-04, 3.0198e-04, 3.6090e-03, 2.6019e-03, 2.1732e-04,\n",
      "         4.2837e-04, 7.9770e-06, 1.1489e-05, 2.6411e-06, 1.0117e-04, 4.6658e-04,\n",
      "         4.2152e-04, 5.7535e-04, 2.9975e-05, 7.3328e-05, 4.4779e-04, 4.8551e-03,\n",
      "         3.8577e-03, 4.3257e-03, 3.4039e-04, 2.8620e-04, 5.5764e-06, 5.0075e-03,\n",
      "         1.8288e-04, 2.4694e-04, 5.3909e-05, 2.2587e-03, 4.7956e-05, 1.8179e-03,\n",
      "         6.7520e-04, 3.6343e-04, 6.3329e-03, 3.9789e-04, 2.3505e-04, 5.9825e-09,\n",
      "         4.7727e-04, 9.6603e-05, 5.0054e-03, 1.0437e-03],\n",
      "        [2.6561e-06, 9.3531e-06, 2.2761e-04, 3.3806e-03, 1.3117e-05, 1.0739e-04,\n",
      "         6.1340e-05, 6.1968e-06, 8.1040e-05, 3.0641e-04, 1.1544e-05, 1.2962e-05,\n",
      "         4.2817e-04, 8.0836e-05, 8.4481e-05, 8.3125e-05, 1.4681e-03, 3.8774e-04,\n",
      "         1.9937e-04, 1.3698e-07, 4.7705e-05, 2.5440e-04, 1.1247e-02, 4.5552e-07,\n",
      "         3.5694e-06, 5.4350e-03, 8.9811e-04, 1.7114e-04, 1.8749e-04, 1.3363e-05,\n",
      "         2.0362e-04, 1.8493e-04, 4.2076e-06, 5.7184e-07, 2.7908e-05, 1.3933e-02,\n",
      "         3.6804e-04, 6.1109e-05, 1.0562e-05, 1.5496e-04, 2.5871e-04, 5.5763e-04,\n",
      "         2.4781e-04, 1.0662e-04, 3.5568e-03, 1.1909e-02, 7.5131e-05, 5.5780e-05,\n",
      "         4.0226e-05, 1.0748e-05, 2.5218e-04, 7.8610e-05, 5.1592e-03, 1.4941e-04,\n",
      "         1.6202e-03, 7.4626e-07, 3.5627e-05, 5.8445e-03, 6.5999e-05, 2.6628e-10,\n",
      "         3.6195e-05, 4.0354e-03, 1.7310e-05, 3.7854e-03],\n",
      "        [1.1309e-05, 2.6879e-04, 7.3558e-05, 2.6527e-03, 3.8254e-05, 6.9366e-04,\n",
      "         1.2813e-04, 1.1271e-05, 5.7811e-06, 3.7325e-04, 1.3861e-04, 2.7521e-06,\n",
      "         1.1055e-04, 8.4964e-05, 2.0771e-03, 2.9751e-03, 1.1176e-03, 2.1562e-04,\n",
      "         1.7878e-04, 6.8023e-06, 8.1698e-03, 5.8499e-03, 4.7873e-04, 3.8173e-06,\n",
      "         3.7762e-06, 2.9106e-04, 7.5900e-04, 1.0646e-03, 5.3965e-04, 6.2286e-05,\n",
      "         1.0522e-04, 1.0194e-05, 5.0665e-06, 1.1644e-06, 1.0353e-04, 3.2729e-04,\n",
      "         5.0933e-04, 1.0797e-04, 4.0178e-04, 7.0512e-05, 2.8072e-04, 6.6640e-03,\n",
      "         2.2125e-04, 9.5707e-03, 1.3179e-03, 2.7743e-04, 4.9310e-06, 1.1070e-03,\n",
      "         7.6651e-05, 6.6183e-05, 1.8177e-05, 2.4570e-04, 1.1251e-04, 2.3701e-04,\n",
      "         1.6277e-03, 4.8575e-05, 7.7154e-03, 1.7327e-03, 3.6634e-04, 5.9991e-11,\n",
      "         4.0104e-04, 2.4623e-04, 1.9379e-03, 2.1698e-04],\n",
      "        [5.1316e-06, 3.9797e-04, 1.2645e-03, 9.3396e-03, 6.3092e-05, 1.5949e-04,\n",
      "         1.1881e-04, 8.7201e-06, 4.7116e-07, 9.7358e-06, 3.1328e-04, 1.0710e-05,\n",
      "         1.5784e-04, 4.7505e-05, 3.3834e-04, 2.6314e-04, 4.5849e-03, 3.2177e-04,\n",
      "         9.7748e-04, 5.8429e-06, 3.5750e-04, 6.8059e-04, 4.0331e-05, 3.8160e-06,\n",
      "         2.9832e-06, 1.1827e-03, 4.0724e-03, 6.7304e-05, 3.4520e-04, 3.8411e-04,\n",
      "         8.6784e-05, 3.5287e-05, 4.8034e-05, 1.0984e-05, 1.6166e-04, 1.4217e-04,\n",
      "         3.4588e-04, 1.0590e-05, 9.5894e-05, 9.7848e-05, 8.7347e-05, 3.3474e-03,\n",
      "         1.5401e-04, 6.0899e-04, 7.8273e-03, 1.5518e-04, 2.0792e-05, 9.9333e-05,\n",
      "         2.5404e-05, 1.7514e-05, 4.4748e-05, 1.3418e-04, 8.7772e-04, 8.1255e-04,\n",
      "         8.0990e-03, 1.6369e-05, 4.1441e-04, 2.8444e-03, 8.5878e-05, 3.1619e-11,\n",
      "         7.8518e-05, 4.2200e-04, 2.2154e-05, 6.2981e-05],\n",
      "        [4.1234e-05, 8.6418e-05, 1.8914e-04, 2.3980e-04, 2.2034e-06, 1.1017e-04,\n",
      "         1.7241e-03, 4.6592e-05, 1.4527e-04, 9.3969e-03, 1.1164e-04, 1.9347e-05,\n",
      "         3.5678e-04, 4.7883e-03, 5.1490e-04, 1.7553e-04, 7.6183e-05, 2.2816e-04,\n",
      "         5.7638e-04, 8.6959e-07, 2.5422e-03, 2.7337e-03, 9.6766e-03, 6.3478e-07,\n",
      "         2.0038e-06, 1.2156e-03, 4.3578e-04, 4.1045e-03, 2.2241e-04, 2.1181e-04,\n",
      "         1.3080e-03, 2.6378e-05, 4.2226e-05, 1.9739e-05, 2.0273e-05, 3.8175e-03,\n",
      "         1.9783e-03, 3.6547e-03, 5.5089e-05, 8.4570e-05, 2.8132e-03, 4.0964e-04,\n",
      "         1.6946e-03, 6.3677e-04, 1.6916e-04, 4.0120e-03, 3.6103e-06, 1.3213e-04,\n",
      "         5.8890e-05, 6.9878e-05, 5.9717e-05, 1.0631e-03, 5.5269e-04, 1.4137e-03,\n",
      "         1.0099e-04, 9.7276e-05, 1.6637e-04, 3.6001e-04, 4.1547e-05, 9.2326e-10,\n",
      "         1.3730e-04, 1.0714e-03, 1.4440e-04, 1.0531e-02],\n",
      "        [4.6148e-06, 5.4602e-05, 2.6673e-05, 5.9405e-04, 2.6433e-06, 1.2805e-03,\n",
      "         6.4936e-04, 8.9534e-06, 9.5573e-06, 1.6526e-04, 4.6374e-04, 2.4344e-05,\n",
      "         7.6101e-04, 6.3664e-05, 6.7481e-04, 1.6934e-03, 4.1299e-04, 1.8916e-04,\n",
      "         3.7590e-04, 9.4195e-06, 3.6665e-04, 4.7268e-04, 6.2545e-04, 3.2661e-05,\n",
      "         1.6038e-06, 1.8283e-04, 7.6535e-04, 5.7430e-04, 3.7495e-04, 2.8371e-05,\n",
      "         9.7615e-04, 5.9481e-06, 2.2854e-05, 1.2445e-06, 4.7114e-04, 5.7027e-04,\n",
      "         1.6382e-04, 7.1331e-05, 1.0255e-04, 1.6099e-04, 5.0110e-04, 7.3056e-04,\n",
      "         3.8673e-04, 4.0860e-04, 3.6084e-04, 3.6564e-04, 3.3205e-06, 1.5052e-03,\n",
      "         6.5719e-04, 3.7422e-05, 1.1424e-05, 3.8222e-04, 4.4701e-05, 6.1089e-04,\n",
      "         4.4008e-04, 2.0611e-05, 8.2164e-04, 3.1836e-04, 1.2158e-03, 4.0874e-11,\n",
      "         9.9986e-06, 5.6143e-05, 4.6974e-04, 2.2863e-04],\n",
      "        [4.2231e-06, 8.2340e-06, 5.5661e-05, 2.1004e-04, 1.8631e-06, 3.2681e-04,\n",
      "         2.5317e-04, 8.9826e-06, 2.3377e-04, 6.6816e-03, 2.3404e-04, 1.2092e-05,\n",
      "         1.7407e-04, 2.7830e-03, 2.0386e-04, 4.8117e-04, 1.9155e-05, 3.8743e-04,\n",
      "         1.0485e-04, 1.2309e-07, 1.5325e-03, 1.0844e-03, 2.1189e-02, 5.7349e-07,\n",
      "         1.6690e-06, 1.8420e-03, 2.1177e-04, 1.3098e-03, 2.9946e-04, 2.0876e-05,\n",
      "         2.1342e-04, 1.4792e-04, 2.4380e-05, 1.6891e-05, 3.4869e-05, 1.7264e-02,\n",
      "         1.2621e-03, 1.7604e-03, 1.7064e-04, 6.7255e-05, 7.4954e-04, 1.6332e-04,\n",
      "         1.1142e-04, 4.9184e-04, 6.7462e-04, 1.5406e-02, 4.6959e-05, 3.7598e-04,\n",
      "         4.4359e-05, 2.9294e-05, 1.1804e-04, 1.3615e-04, 2.7412e-03, 6.8589e-05,\n",
      "         1.7150e-04, 1.0845e-05, 3.7675e-04, 1.5465e-03, 2.3271e-04, 5.1179e-10,\n",
      "         5.8905e-05, 2.0981e-03, 1.8812e-04, 1.2163e-02]])}, 139938764448680: {'step': 4690, 'exp_avg': tensor([ 6.7802e-03, -1.5579e-03,  9.7195e-03, -7.1497e-03, -1.6484e-02,\n",
      "         9.7807e-03, -4.8916e-03,  5.7760e-03, -2.0609e-03,  8.7392e-05]), 'exp_avg_sq': tensor([0.0003, 0.0004, 0.0005, 0.0006, 0.0005, 0.0007, 0.0004, 0.0005, 0.0008,\n",
      "        0.0007])}}\n",
      "param_groups \t [{'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False, 'params': [139938764448248, 139938764448320, 139938764448032, 139938764448392, 139938764448464, 139938764448536, 139938764448608, 139938764448680]}]\n"
     ]
    }
   ],
   "source": [
    "# Print optimizer's state_dict\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98bee7eaf09d225730006f2b24ca5662d28cfb65"
   },
   "source": [
    "# Kaggle- Multilayered Perceptron (MLP) implemention on MNIST dataset\n",
    "Untill now we were using the MNIST dataset that is available in torchvision.dataset.Let us now load the dataset from Kaggle repo and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "4e83a9e422c10eb07cbfb779be01803d2b8a5334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "PATH=Path(\"../input/digit-recognizer\")\n",
    "print(os.listdir(\"../input/digit-recognizer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "661e23266c2c882d34cdae4c9074d26c0d2ac040"
   },
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "72b61aac15c29fc295d77130b07d1110c9cb1825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(PATH/'train.csv')\n",
    "test=pd.read_csv(PATH/'test.csv')\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d5eb02dbfc5e385ffd113560494e0b2275e5f66"
   },
   "source": [
    "## Extracting Input and Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "858a074c0e1dea92562d0f1bd93ff5302f861643"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (42000,))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=train.drop(\"label\",axis=1)\n",
    "y=np.array(train['label'])\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "387109d77b8c6f76d4de868158340faf1a38b2dc"
   },
   "source": [
    "## Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "_uuid": "b8ff683f50227c31ee39ec05a7bb8b4e2a8c5f94"
   },
   "outputs": [],
   "source": [
    "#x_train=x/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "614e6245bdf2e3372dca00d5111b3fbe8e993a64"
   },
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "_uuid": "65e189e8b8c6232146d0dde1fceb773353ad8389"
   },
   "outputs": [],
   "source": [
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f37069db924850a07cd3e98378ae9c61bab1f8f"
   },
   "source": [
    "## Train Test in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "_uuid": "709aaea373c664fad6fd42d8779ae091145b8308"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# create feature and targets tensor for train set.\\ntorch_X_train = torch.from_numpy(x_train.values).type(torch.FloatTensor)\\ntorch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\\n\\n# create feature and targets tensor for test set.\\ntorch_X_test = torch.from_numpy(x_test.values).type(torch.FloatTensor)\\ntorch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\\n\\n# Pytorch train and test sets\\ntrain = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\\ntest = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\\n'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# create feature and targets tensor for train set.\n",
    "torch_X_train = torch.from_numpy(x_train.values).type(torch.FloatTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(x_test.values).type(torch.FloatTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "80525db377fe319e7a3fc538ef8b76639c28c995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBATCH_SIZE=64\\n# data loader\\ntrain_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\\ntest_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\\n'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "BATCH_SIZE=64\n",
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "454f4fb8e0a416e60aed471a49850c01a64a77e6"
   },
   "source": [
    "## Train -Test Split -Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "_uuid": "d616496f4e453322efe8aecfa71b17fcdddaa8dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of trainSet 33600 , len of testSet 8400\n"
     ]
    }
   ],
   "source": [
    "torch_X_train = torch.from_numpy(x.values).type(torch.FloatTensor)/255\n",
    "torch_y_train = torch.from_numpy(y).type(torch.LongTensor)\n",
    "myDataset = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "valid_no  = int(0.2 * len(myDataset))\n",
    "# so divide the data into trainset and testset\n",
    "trainSet,testSet = torch.utils.data.random_split(myDataset,(len(myDataset)-valid_no,valid_no))\n",
    "print(f\"len of trainSet {len(trainSet)} , len of testSet {len(testSet)}\")\n",
    "batch_size=64\n",
    "train_loader  = DataLoader(trainSet , batch_size=batch_size ,shuffle=True) \n",
    "test_loader  = DataLoader(testSet , batch_size=batch_size ,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a06249ad57104d74d0258fd5972961f720bdc3cf"
   },
   "source": [
    "trainData = torch.from_numpy(x_train.values)\n",
    "trainLabel=torch.from_numpy(y_train)\n",
    "testData = torch.from_numpy(x_test.values)\n",
    "testLabel = torch.from_numpy(y_test)\n",
    "trainData, testData = trainData.type(torch.FloatTensor), testData.type(torch.LongTensor)\n",
    "trainLabel, testLabel = trainLabel.type(torch.FloatTensor), testLabel.type(torch.LongTensor)\n",
    "trainData.shape,testData.shape\n",
    "trainData = trainData.unsqueeze_(dim=1)\n",
    "testData = testData.unsqueeze_(dim=1)\n",
    "trainData.shape,testData.shape\n",
    "transforms =transforms.Compose(transforms.ToTensor())\n",
    "train_dataset = TensorDataset(trainData,trainLabel)\n",
    "train_loader = DataLoader(train_dataset,batch_size=64,shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(testData,testLabel)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "97b2925a24f59b10a16864a76f00e02a4c92b36f"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "_uuid": "8cbe1c508bacadbb875014318a35fed17ab6a3a1"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "        # Dropout module with 0.2 drop probability\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Now with dropout\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "\n",
    "        # output so no dropout here\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model=Network()\n",
    "optimizer=optim.Adam(model.parameters(),lr=0.01)\n",
    "criterion=nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2bea512cd5bd9f4f41bd77044f471e644505a5fa"
   },
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "_uuid": "2df4882ed86f9b17b4bba52d56adfde46d1f718d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.446..  Test Loss: 0.214..  Test Accuracy: 0.943\n",
      "Epoch: 2/5..  Training Loss: 0.307..  Test Loss: 0.192..  Test Accuracy: 0.953\n",
      "Epoch: 3/5..  Training Loss: 0.286..  Test Loss: 0.231..  Test Accuracy: 0.948\n",
      "Epoch: 4/5..  Training Loss: 0.280..  Test Loss: 0.199..  Test Accuracy: 0.949\n",
      "Epoch: 5/5..  Training Loss: 0.267..  Test Loss: 0.206..  Test Accuracy: 0.953\n"
     ]
    }
   ],
   "source": [
    "epochs=5\n",
    "train_losses,test_losses=[],[]\n",
    "for e in range(epochs):\n",
    "    running_loss=0\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        log_ps=model(images)\n",
    "        loss=criterion(log_ps,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+=loss.item()\n",
    "        \n",
    "    else:\n",
    "        test_loss=0\n",
    "        accuracy=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for images,labels in test_loader:\n",
    "                log_ps=model(images)\n",
    "                test_loss+=criterion(log_ps,labels)\n",
    "                ps=torch.exp(log_ps)\n",
    "                top_p,top_class=ps.topk(1,dim=1)\n",
    "                equals=top_class==labels.view(*top_class.shape)\n",
    "                accuracy+=torch.mean(equals.type(torch.FloatTensor))\n",
    "        model.train()\n",
    "        train_losses.append(running_loss/len(train_loader))\n",
    "        test_losses.append(test_loss/len(test_loader))\n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9373aea13cc5891684fb8b801cbcd0ac17eff458"
   },
   "source": [
    "## Save our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "_uuid": "bfcc3f17cadca0bf48cec130586b907965905ed6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model: \n",
      "\n",
      " Network(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2)\n",
      ") \n",
      "\n",
      "The state dict keys: \n",
      "\n",
      " odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Our model: \\n\\n\", model, '\\n')\n",
    "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "_uuid": "f83335753469344d38ac362053a74fad30b0ca3e"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70b1a508fd748a8823a9e1af57538e4cacb0621d"
   },
   "source": [
    "## Load our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "abd854b1c8bfed532cb4e64578c40fd29dea9a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('checkpoint.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "7a889737952161eb1834f521476f0f1c8448570a"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "_uuid": "a08eff1adeb3a8f8f7a31356828ee732a557c3d5"
   },
   "outputs": [],
   "source": [
    "checkpoint = {'input_size': 784,\n",
    "              'output_size': 10,\n",
    "              'hidden_layers': [256,128,64],\n",
    "              'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3356c9580d6c01685a52a11f906ee1c9dbe7ef1"
   },
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "34abb15aa48ad4f133ee15a2f9a5268b45692c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 784])\n"
     ]
    }
   ],
   "source": [
    "test_images = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "test_image = test_images.loc[:,test_images.columns != \"label\"].values\n",
    "test_dataset = torch.from_numpy(test_image).type(torch.FloatTensor)/255\n",
    "print(test_dataset.shape)\n",
    "#test_dataset = torch.utils.data.TensorDataset(test_dataset)\n",
    "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "790dd7f94c59a6de5441827b999b6cff6f686154"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images in new_test_loader:\n",
    "        output = model(images)\n",
    "        ps = torch.exp(output)\n",
    "        top_p, top_class = ps.topk(1, dim = 1)\n",
    "        results += top_class.numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0f9b334b1c25c4bb1a48fda6b64634f1f90b7565"
   },
   "source": [
    "## Check the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "56ffd3051274596232af3ca4d1a9ee7d6322881a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 9 8 3]\n",
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.array(results).flatten()\n",
    "print(predictions[:5])\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f946013a3eab6274d1becd93dfe99aa9f7491cf9"
   },
   "source": [
    "## Submit for Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "655160a6e2d490651c0fe70b8ba7480ed8ba1fcc"
   },
   "outputs": [],
   "source": [
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "177c548a264bbaaa76e216eeaf1d747db88b1030"
   },
   "source": [
    "# Reference\n",
    "\n",
    "[Introduction to Pytorch-Udacity](https://github.com/udacity/deep-learning-v2-pytorch/tree/master/intro-to-pytorch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
